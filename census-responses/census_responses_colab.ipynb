{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "census-responses-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0TAdi8gb4oZK",
        "WAjhY7qa-UCO",
        "2tN9xyjpHg9t",
        "kmLScMTr4oZQ"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdiffendal/USAT/blob/master/census-responses/census_responses_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbXbhig24oZG",
        "colab_type": "text"
      },
      "source": [
        "# 2020 Census Response Rate Analysis\n",
        "\n",
        "### Theresa Diffendal, USA Today data intern, 06/2020\n",
        "\n",
        "#### 2020 response rates from: https://2020census.gov/en/response-rates.html\n",
        "#### 2010 response rates from: https://api.census.gov/data/2010/dec/responserate/variables.html\n",
        "#### Demographic information in 2014-2018 ACS 5-year-estimate from: https://data2.nhgis.org/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TAdi8gb4oZK",
        "colab_type": "text"
      },
      "source": [
        "## Column Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dWSiayi_y6Z",
        "colab_type": "text"
      },
      "source": [
        "GEO_ID = Geographic Identifier\n",
        "\n",
        "RESP_DATE = Posting Date\n",
        "\n",
        "State = name of state (one of the 50 states, District of Columbia, Puerto Rico, or NaN)\n",
        "\n",
        "Geo_Name = name of the tract, county, state\n",
        "\n",
        "Region = region of the U.S. in which state is located as defined by census map at https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
        "\n",
        "Geo_Type = type of geography; possible answers include Census Tract, Congressional District, Consolidated City, Country, County, County Subdivision, Place, Region, State, Tribal Tract, Tribal Area\n",
        "\n",
        "DRRINT = Daily Self-Response Rate - Internet\n",
        "\n",
        "DRRALL = Daily Self-Response Rate – Overall\n",
        "\n",
        "CRRINT = Cumulative Self-Response Rate - Internet; renamed internet\n",
        "\n",
        "not_int = new calculated column showing response rate NOT from internet\n",
        "\n",
        "CRRALL = Cumulative Self-Response Rate – Overall; renamed 2020_rate\n",
        "\n",
        "DINTMIN = Minimum Daily Internet Self-Response Rate\n",
        "\n",
        "DMIN = Minimum Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMIN = Minimum Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMIN = Minimum Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTMAX = Maximum Daily Internet Self-Response Rate\n",
        "\n",
        "DMAX = Maximum Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMAX = Maximum Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMAX = Maximum Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTAVG = Average Daily Internet Self-Response Rate\n",
        "\n",
        "DAVG = Average Daily Overall Self-Response Rate\n",
        "\n",
        "CINTAVG = Average Cumulative Internet Self-Response Rate\n",
        "\n",
        "CAVG = Average Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTMED = Median Daily Internet Self-Response Rate\n",
        "\n",
        "DMED = Median Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMED = Median Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMED = Median Cumulative Overall Self-Response Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxd7lfhbqD3W",
        "colab_type": "text"
      },
      "source": [
        "## Read, Merge, Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDwZx7aHAWpf",
        "colab_type": "text"
      },
      "source": [
        "### Initial Load and Merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzhO6z06yH99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "425f356e-a3bc-436c-a74a-1701fc879793"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip_J3r424oZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in 2020 response rates\n",
        "initial_df = pd.read_csv('https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/decennialrr2020.csv',\n",
        "                         dtype={'CRRINT':np.float,\n",
        "                                'CRRALL':np.float})\n",
        "# read in as latin-1 since the automatic detection returns an error\n",
        "crosswalk = pd.read_csv('https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/decennialrr2020_crosswalkfile.csv', encoding='latin-1')\n",
        "# states paired with region as defined by census map at https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
        "regions = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/state_region.csv')\n",
        "\n",
        "# merge responses and crosswalk\n",
        "temp = pd.merge(initial_df, crosswalk, on='GEO_ID')\n",
        "\n",
        "#merge merged1 with region data\n",
        "merged = pd.merge(temp, regions, on='State')\n",
        "\n",
        "# create column showing responses not from internet\n",
        "merged['not_int'] = merged.CRRALL - merged.CRRINT\n",
        "merged['not_int_pct'] = (merged.not_int) * 100 / merged.CRRALL\n",
        "\n",
        "#reorder columns to move State, Geo_Name and Geo_Type to front; also going to drop some values\n",
        "cols = ['GEO_ID', 'RESP_DATE', 'State', 'Geo_Name', 'Region', 'Geo_Type', \n",
        "        'CRRINT', 'not_int', 'not_int_pct', 'CRRALL']\n",
        "merged = merged[cols].rename(columns={'CRRINT':'internet', 'CRRALL':'2020_rate'})"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppli4PGC4oZd",
        "colab_type": "text"
      },
      "source": [
        "### States"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxWiGJyALk8C",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxRHegvy4oZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create df with response rate by state\n",
        "states2020 = merged[merged['Geo_Type'] == 'State']\n",
        "states2020 = states2020.rename(columns={\"internet\": \"state_internet\", \n",
        "                                        \"not_int\" : \"state_not_int\", \n",
        "                                        'not_int_pct' : 'state_not_int_pct',\n",
        "                                        \"2020_rate\" : \"2020_state_rate\"})\n",
        "\n",
        "# print df and sort by highest cumulative response rate\n",
        "#states2020.sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDPo55jgLtGy",
        "colab_type": "text"
      },
      "source": [
        "#### Join 2010 states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HDvnJhF4oaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in csvs with 2010 response data for states\n",
        "states2010 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/states2010.csv',\n",
        "                         dtype={'2010_rate':np.float,\n",
        "                                '2000_rate':np.float})\n",
        "\n",
        "# merge with 2020 states\n",
        "states = pd.merge(states2020, states2010, on='State')\n",
        "#only select columns we want\n",
        "cols = ['GEO_ID', 'State', 'Region',\n",
        " '2020_state_rate', '2010_rate', '2000_rate']\n",
        "states = states[cols].rename(\n",
        "    columns={'2000_rate':'2000_state_rate', '2010_rate':'2010_state_rate'})\n",
        "\n",
        "#create column with difference in 2010 vs 2020 response rate\n",
        "states['10_20_state_difference'] = (\n",
        "    states['2020_state_rate'] - states['2010_state_rate']\n",
        "    ) * 100 / states['2010_state_rate']\n",
        "\n",
        "#print table sorted by 10-20 difference largest ---> smallest\n",
        "#states.sort_values(by=['2000_state_rate'], ascending=True)"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QutNTWkb4oZN",
        "colab_type": "text"
      },
      "source": [
        "### Census Tracts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYFZkXWy_ehB",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Tracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "poLTe8ZR4oZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select just census tract geo types\n",
        "tracts2020 = merged[merged['Geo_Type'].str.contains(\"Tract\")].rename(\n",
        "    columns={\"2020_rate\": \"2020_tract_rate\",'not_int':'tract_not_int',\n",
        "             'not_int_pct':'tract_not_int_pct'})\n",
        "# sort by highest cumulative response rate\n",
        "#tracts2020.sort_values(by='2020_tract_rate', ascending=False)"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHSpstWKIYJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ae614b63-41f7-44d8-97d9-b6e102340bc3"
      },
      "source": [
        "#tract rates compared to state averages\n",
        "tract2020states = pd.merge(tracts2020, states, on=['State', 'Region'])\n",
        "tract2020states = tract2020states[['GEO_ID_x', 'State', 'Geo_Name', 'Geo_Type', \n",
        "                                   'Region','2020_tract_rate', '2020_state_rate', \n",
        "                                   '2010_state_rate', '10_20_state_difference']\n",
        "                                  ].rename(columns={'GEO_ID_x':'GEO_ID'})\n",
        "tract2020states['2020_tract_st_diff'] = tract2020states['2020_tract_rate'] - tract2020states['2020_state_rate']\n",
        "tract2020states.sort_values(by=['2020_tract_st_diff'])\n",
        "\n",
        "print(\n",
        "    \"Difference in records:\", len(tracts2020) - len(tract2020states), \"\\n\",\n",
        "    \"Number of tribal tracts:\", len(tracts2020[tracts2020['Geo_Type'].str.contains(\"Tribal\")]),\n",
        "    \"\\n\\n\", \"merging tracts with states will drop tribal tracts\", \"\\n\",\n",
        "    \"(as they have no state), so those are examined separately below\"\n",
        ")"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Difference in records: 426 \n",
            " Number of tribal tracts: 426 \n",
            "\n",
            " merging tracts with states will drop tribal tracts \n",
            " (as they have no state), so those are examined separately below\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw37IfN-MoJt",
        "colab_type": "text"
      },
      "source": [
        "#### Join 2010 tract rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzl46WTuLqog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in csvs with 2010 response data for tracts and states\n",
        "tracts2010 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/2010responserate.csv',\n",
        "                         dtype={'FSRR2010':np.float}).rename(\n",
        "                             columns={'FSRR2010':'2010_tract_rate'})\n",
        "#tracts2010"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8wlaOo84oZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## difference in row numbers: both tract dfs have 84519 rows, but when joined only 84093\n",
        "# Identify what values are in tracts2010 and not in tracts2020\n",
        "#key_diff1 = set(tracts2010.GEO_ID).difference(tracts2020.GEO_ID)\n",
        "#len(key_diff1)\n",
        "#key_diff1\n",
        "\n",
        "# Identify what values are in tracts2020 and not in tracts2010\n",
        "#key_diff2 = set(tracts2020.GEO_ID).difference(tracts2010.GEO_ID)\n",
        "#len(key_diff2)\n",
        "#key_diff2\n",
        "\n",
        "# 2010 rates do not include the 426 tribal tracts\n",
        "# Those differences account for 426 tracts, which is .5% of the original 84519 \n",
        "# tracts. These tracts are dropped in the comparative analyses and are analyzed separately"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkzjcuo4oZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge with 2020 tracts\n",
        "tracts = pd.merge(tract2020states, tracts2010, on='GEO_ID')\n",
        "#select only columns we want\n",
        "cols = ['Geo_Name','county', 'State_y', 'Region', 'Geo_Type', '2020_tract_rate', \n",
        "        '2010_tract_rate', '2020_tract_st_diff', '2020_state_rate', \n",
        "        '2010_state_rate', '10_20_state_difference', 'GEO_ID']\n",
        "tracts = tracts[cols].rename(columns={'State_y':'State'})\n",
        "#print df sorted largest --> smallest 2010 rate\n",
        "#tracts.sort_values(by='2010_tract_rate', ascending=False)"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19V3l294oZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "5b53315f-2ba2-48ac-c71f-41db22dabd4d"
      },
      "source": [
        "#how many null 2010 response values are there\n",
        "no_2010 = tracts.isnull().any(axis=1)\n",
        "no_2010 = tracts[no_2010].sort_values(by=\"2010_tract_rate\")\n",
        "\n",
        "#tracts2010[tracts2010['2010_tract_rate'] == 0]\n",
        "\n",
        "print(\n",
        "    \"There are\", len(no_2010), \"null 2010 response rate values out of\", \n",
        "    len(tracts2010), \"total 2010 observations, \\n or\",\n",
        "    len(no_2010) * 100 / len(tracts2010) , \"% \\n\",\n",
        "    \"and\", len(no_2010) * 100 / len(tracts), \"% of the\", len(tracts),\n",
        "    \"total of 2020 and 2010 tracts \\n\\n\",\n",
        "    \"0 response rate traacts in each state:\", \"\\n\",\n",
        "    no_2010['State'].value_counts())"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 531 null 2010 response rate values out of 84519 total 2010 observations, \n",
            " or 0.6282611010542009 % \n",
            " and 0.6314437586957298 % of the 84093 total of 2020 and 2010 tracts \n",
            "\n",
            " 0 response rate traacts in each state: \n",
            "  Wisconsin               92\n",
            " Florida                 56\n",
            " California              54\n",
            " Texas                   54\n",
            " Arizona                 50\n",
            " New York                50\n",
            " New Mexico              30\n",
            " Massachusetts           21\n",
            " Washington              17\n",
            " Montana                 14\n",
            " South Dakota            13\n",
            " North Carolina           8\n",
            " Alabama                  7\n",
            " Minnesota                7\n",
            " Utah                     6\n",
            " Colorado                 6\n",
            " Wyoming                  6\n",
            " Idaho                    6\n",
            " North Dakota             6\n",
            " Virginia                 3\n",
            " Maine                    3\n",
            " Nevada                   3\n",
            " New Hampshire            3\n",
            " Vermont                  3\n",
            " Oklahoma                 2\n",
            " Nebraska                 2\n",
            " New Jersey               2\n",
            " Alaska                   1\n",
            " Delaware                 1\n",
            " South Carolina           1\n",
            " Rhode Island             1\n",
            " District of Columbia     1\n",
            " Pennsylvania             1\n",
            " Tennessee                1\n",
            "Name: State, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1oLIOrq4oZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create column with difference in 2010 vs 2020 response rate\n",
        "tracts['10_20_tract_difference'] = (tracts['2020_tract_rate'] - tracts['2010_tract_rate']) / tracts['2010_tract_rate']\n",
        "#sort df largest --> smallest 10-20 difference\n",
        "#tracts.sort_values(by='10_20_tract_difference', ascending=False)"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsbRp_m3bStQ",
        "colab_type": "text"
      },
      "source": [
        "### Census API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq8ETNnbHs89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#try something new\n",
        "%matplotlib inline\n",
        "import requests, pandas as pd\n",
        "\n",
        "key = 'https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/census_key.txt'\n",
        "api_key = requests.get(key).text\n",
        "\n",
        "year='2018'\n",
        "dsource='acs'\n",
        "dname='acs5'\n",
        "cols=['GEO_ID', 'TRACT', 'STATE', 'B00001_001E', 'B00002_001E']\n",
        "#names=['GEO_ID', 'total_pop', 'housing_units',]\n",
        "state='*'\n",
        "county='*'\n",
        "tract='*'\n",
        "\n",
        "base_url = f'https://api.census.gov/data/{year}/{dsource}/{dname}'\n"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEBCtxfT2KAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftKA9hxg4oaM",
        "colab_type": "text"
      },
      "source": [
        "### Demographic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DPPCZkNJTia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "53274750-81d4-494a-9901-341be084d222"
      },
      "source": [
        "#load census demographic data, join\n",
        "\n",
        "## demographics data\n",
        "temp1 = pd.read_csv('/content/drive/Shared drives/Shared Items/census-responses/data/acs_demographics/ACSDP5Y2018.DP05_data_with_overlays_2020-07-02T144029.csv',\n",
        "                    usecols = [0,1,2,70,148,152,156,176,208,228,232,284,304,342],\n",
        "                    names = ['GEO_ID', 'NAME','total_population','median_age', \n",
        "                             'white_pct','black_pct','native_pct','asian_pct',\n",
        "                             'pacific_pct','other_pct','two_pct','latino_pct',\n",
        "                             'notLatino_pct','house_units'], \n",
        "                    skiprows= 1#,\n",
        "#                    keep_default_na=True,\n",
        "#                    na_values=['-','**'],\n",
        "#                    error_bad_lines=False,\n",
        "#                    dtype={'total_population':np.int,'median_age':np.float, \n",
        "#                          'white_pct':np.float,'black_pct':np.float,\n",
        "#                           'native_pct':np.float,'asian_pct':np.float,\n",
        "#                           'pacific_pct':np.float,'other_pct':np.float,\n",
        "#                           'two_pct':np.float,'latino_pct':np.float,\n",
        "#                           'notLatino_pct':np.float,'house_units':np.int}\n",
        "                    )\n",
        "\n",
        "### housing data\n",
        "temp2 = pd.read_csv('/content/drive/Shared drives/Shared Items/census-responses/data/acs_housing/ACSDP5Y2018.DP04_data_with_overlays_2020-07-02T161352.csv',\n",
        "                    usecols = [0,1,8,12,28,52,56,184,188,300,354,568],\n",
        "                    names = ['GEO_ID', 'NAME','occupied_pct','vacant_pct', \n",
        "                             'house_pct','bigapt_pct','mobilehome_pct',\n",
        "                             'owner_pct','renter_pct','no_telephone_pct',\n",
        "                             'median_value','rent_more_35_pct'],\n",
        "#                    keep_default_na=True,\n",
        "#                   na_values=['-','**'],\n",
        "#                   error_bad_lines=False,\n",
        "#                    dtype={'occupied_pct':np.float,'vacant_pct':np.float,\n",
        "#                           'house_pct':np.float,'bigapt_pct':np.float,\n",
        "#                           'mobilehome_pct':np.float,'owner_pct':np.float,\n",
        "#                           'renter_pct':np.float,'no_telephone_pct':np.float,\n",
        "#                           'median_value':np.float,'rent_more_35_pct':np.float},\n",
        "                    skiprows=2)\n",
        "\n",
        "## income data\n",
        "temp3 = pd.read_csv('/content/drive/Shared drives/Shared Items/census-responses/data/acs_income/ACSST5Y2018.S1901_data_with_overlays_2020-07-02T160659.csv',\n",
        "                    usecols = [0,1,90],\n",
        "                    names = ['GEO_ID', 'NAME','median_income'],\n",
        "#                    dtype={'median_income':np.float},\n",
        "                    skiprows=2)\n",
        "\n",
        "## internet access data\n",
        "temp4 = pd.read_csv('/content/drive/Shared drives/Shared Items/census-responses/data/acs_internet_access/ACSDT5Y2018.B28002_data_with_overlays_2020-07-02T154751.csv',\n",
        "                    usecols = [0,1,2,26],\n",
        "                    names = ['GEO_ID', 'NAME','total_comp', 'no_int'],\n",
        "#                    dtype={'total_comp':np.int, 'no_int':np.int},\n",
        "                    skiprows=2)\n",
        "\n",
        "#create new column to get % without internet instead of whole number\n",
        "temp4['no_int_pct'] = temp4.no_int * 100 / temp4.total_comp\n",
        "cols = ['GEO_ID', 'NAME', 'no_int_pct']\n",
        "temp4 = temp4[cols]"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (8,12,28,52,56,184,188,300) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yru8DdppJTN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## merge demographic and response rate data\n",
        "\n",
        "frames = [temp1, temp2, temp3, temp4]\n",
        "\n",
        "# merge to create new df with all demos for all tracts\n",
        "from functools import reduce\n",
        "demo = reduce(lambda  left,right: pd.merge(left,right,on=['GEO_ID', 'NAME'],\n",
        "                                            how='left'), frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RybVmYuM2YF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dataframe with demographics and response rates \n",
        "temp = pd.merge(tracts, demo, on=['GEO_ID'], how = 'left')\n",
        "\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXDKEcREPtvw",
        "colab_type": "text"
      },
      "source": [
        "#### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QapgMX_MmHHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## difference in row numbers\n",
        "# Identify what values are in tracts and not in demo\n",
        "key_diff1 = pd.DataFrame(list(set(tracts.GEO_ID).difference(demo.GEO_ID))\n",
        ").rename(columns={0:'GEO_ID'})\n",
        "\n",
        "# Identify what values are in demo and not in tracts\n",
        "key_diff2 = pd.DataFrame(list(set(demo.GEO_ID).difference(tracts.GEO_ID))\n",
        ").rename(columns={0:'GEO_ID'})\n",
        "\n",
        "print(\"There are\", len(tracts), \"observations in the tracts df and \\n\",\n",
        "    \"There are\", len(demo), \"observations in the demographics df, \\n\",\n",
        "    \"a difference of\", len(tracts) - len(demo), \"\\n\\n\",\n",
        "    \"There are\", len(key_diff1), \n",
        "    \"tracts in the tracts df that are not in the demographics df \\n\",\n",
        "    \"And there are\", len(key_diff2), \"tracts in the demo df not in the tracts df\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp4VrACeQTt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a dataframe of all rows with na value\n",
        "temp1 = temp[temp.isna().any(axis=1)]\n",
        "\n",
        "# how many nas in each state\n",
        "temp2 = pd.DataFrame(temp1['State'].value_counts()).reset_index().rename(\n",
        "    columns={'index':'state', 'State':'count_na'})\n",
        "\n",
        "#compare to total \n",
        "temp3 = pd.DataFrame(temp['State'].value_counts()).reset_index().rename(\n",
        "    columns={'index':'state', 'State':'count'})\n",
        "\n",
        "#see what percent of state values of na\n",
        "temp4 = pd.merge(temp2, temp3, on=['state'])\n",
        "temp4['na_percent'] = (temp4['count_na']*100) / temp4['count']\n",
        "\n",
        "print(\n",
        "    \"Total na tracts:\", sum(temp4['count_na']), \"\\n\",\n",
        "    'NAs as % of all tracts:', (sum(temp4['count_na'])*100) / sum(temp4['count']),\n",
        "    \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_8zDZ3ghLTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if any nas\n",
        "#pd.set_option('display.max_rows', None)\n",
        "print(pd.isnull(temp).sum())\n",
        "\n",
        "#still 52 states? (50 + DC and PR)\n",
        "#print(\"Number states: \", len(df['State'].unique()))\n",
        "\n",
        "#compare tract numbers now to before na drop\n",
        "#temp1 = pd.DataFrame(temp.groupby('State')['Geo_Name'].nunique()).rename(columns={'Geo_Name':'beforeDrop'})\n",
        "#temp2 = pd.DataFrame(df.groupby('State')['Geo_Name'].nunique()).rename(columns={'Geo_Name':'afterDrop'})\n",
        "#temp3 = pd.merge(temp1, temp2, left_index = True, right_index=True)\n",
        "#number tracts dropped from each state\n",
        "#temp3['numDrop'] = temp3['beforeDrop'] - temp3['afterDrop']\n",
        "# the percentage of total tracts dropped\n",
        "#temp3['dropPct'] = temp3['numDrop']*100 / temp3['beforeDrop']\n",
        "#temp3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo_-Pu9E4oaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#return column size\n",
        "pd.set_option('display.max_columns', 15)\n",
        "#pd.set_option('display.max_row', 50)\n",
        "\n",
        "#only select columns we want\n",
        "cols = ['Geo_Name', 'county', 'State', '2020_tract_rate',\n",
        " '2010_tract_rate', '2020_tract_st_diff', '2020_state_rate', '2010_state_rate',\n",
        " '10_20_state_difference',  '10_20_tract_difference', 'total_population',\n",
        " 'median_age', 'white_pct', 'black_pct', 'native_pct', 'asian_pct',\n",
        " 'pacific_pct', 'other_pct', 'two_pct', 'latino_pct', 'notLatino_pct',\n",
        " 'house_units', 'occupied_pct', 'vacant_pct', 'house_pct', 'bigapt_pct',\n",
        " 'mobilehome_pct', 'owner_pct', 'renter_pct', 'no_telephone_pct',\n",
        " 'median_value', 'rent_more_35_pct', 'median_income', 'no_int_pct', 'GEO_ID', \n",
        " 'Region']\n",
        "\n",
        "df = temp[cols]\n",
        "#df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdZ0zN4nA1ek",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAjKrWdeyR9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##see all dfs in memory\n",
        "%whos DataFrame\n",
        "\n",
        "#### Existing DFs:\n",
        "\n",
        "#dataframe with all years, states, tracts, demographics\n",
        "#df\n",
        "\n",
        "#2010 and 2020 states\n",
        "#states\n",
        "\n",
        "#2010 States\n",
        "#states2010\n",
        "\n",
        "#2020 States\n",
        "#states2020\n",
        "\n",
        "#2010 and 2020 tracts and states\n",
        "#tracts\n",
        "\n",
        "#2020 tracts paired with states, includes int data\n",
        "#tracts2020states\n",
        "\n",
        "# ignore all dfs with \"temp\" in name "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUrmR-IrfcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get average state rate and see how many are above average\n",
        "\n",
        "print(\n",
        "    \"62.0% is the current nationwide response rate and\",\n",
        "    np.sum(states2020['2020_state_rate'] > 62.0),\n",
        "    \"states exceed that\", \"\\n\")\n",
        "print(states2020[states2020['2020_state_rate'] > 62.0].State.to_list(), \"\\n\")\n",
        "\n",
        "temp = states2020['2020_state_rate'] > 62.0\n",
        "\n",
        "#how many in each region?\n",
        "states2020[temp].Region.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKSDVX0vZAew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#how many tracts are > than state avg?\n",
        "\n",
        "#tract2020States.count(tract2020States['2020_tract_st_diff'] > 0)\n",
        "print(np.sum(tract2020states['2020_tract_st_diff'] > 0), \"tracts out of\", \n",
        "      len(tract2020states), \n",
        "      \"total (\", \n",
        "      (np.sum(tract2020states['2020_tract_st_diff'] > 0) * 100) / len(tract2020states),\n",
        "      \"% ) \\n\",\n",
        "      \"currently have greater census response rates than their state average\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw0UAsUeC_us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get info on 1000 tracks with greatest drop in response rate\n",
        "big_drop = tracts.sort_values(by='10_20_tract_difference', ascending=True).head(1000)\n",
        "big_drop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05uTu0dMD3k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lowest tract rates\n",
        "lowest = tracts.sort_values(by='2020_tract_rate', ascending=True).head(1000)\n",
        "lowest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuG9IMvlwcHv",
        "colab_type": "text"
      },
      "source": [
        "### National Comparative Rankings 2010 vs 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iwBMqvP9xxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Discrepancies? Shouldn't these all match up?\n",
        "# Average is sum / #obs\n",
        "#print(\n",
        "#  \"2010 State Resonse Average from states data:\",\n",
        "#    states.mean(axis=0)['2010_state_rate'], \"\\n\",\n",
        "#  \"2010 States Response Average from df data:\",\n",
        "#    df.mean(axis=0)['2010_state_rate'], \"\\n\",\n",
        "#  \"2010 Tract Response Average from df data:\",\n",
        "#    df.mean(axis=0)['2010_tract_rate'],  \"\\n\"\n",
        "#)\n",
        "## totals intended to be sum(percentages) / 100 (denominator)\n",
        "#print(\n",
        "#  \"2010 State Resonse Total from states data:\",\n",
        "#    (states['2010_state_rate'].sum()) / 100, \"\\n\",\n",
        "#  \"2010 States Response Total from df data:\",\n",
        "#    (df['2010_state_rate'].sum()) / 100, \"\\n\",\n",
        "#  \"2010 Tract Response Total from df data:\",\n",
        "#    (df['2010_tract_rate'].sum()) / 100\n",
        "#)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qw6ix7B4oaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average difference between current state rates and 2010 state rates as of 6/15/20\n",
        "#takes a while to run so commented out\n",
        "#df.mean(axis=0)['10_20_state_difference']\n",
        "\n",
        "#average 2020 response rate across states?\n",
        "#print(\n",
        "#  \"2020 State Resonse Average from states data:\",\n",
        "#    states.mean(axis=0)['2020_state_rate'], \"\\n\",\n",
        "#  \"2020 States Response Average from df data:\",\n",
        "#   df.mean(axis=0)['2020_state_rate'], \"\\n\",\n",
        "#  \"2020 Tract Response Average from df data:\",\n",
        "#    df.mean(axis=0)['2020_tract_rate'], \"\\n\"\n",
        "#)\n",
        "\n",
        "#is the total not sum(numerator) / 100? where numerator is percentage response rate?\n",
        "#print(\n",
        "#  \"2020 State Resonse Total from states data:\",\n",
        "#    (states['2020_state_rate'].sum()) / (100), \"\\n\",\n",
        "#  \"2020 States Response Total from df data:\",\n",
        "#    (df['2020_state_rate'].sum()) / (100), \"\\n\",\n",
        "# \"2020 Tract Response Total from df data:\",\n",
        "#    (df['2020_tract_rate'].sum()) / (100)\n",
        "#)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBtQ-tkD4oaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference by region\n",
        "states.groupby('Region').mean().sort_values(by='10_20_state_difference', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db386fTQ4iiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assign ranks to states based on comparative response rate\n",
        "states['2020_rank'] = states['2020_state_rate'].rank(method='max', ascending=False)\n",
        "states['2010_rank'] = states['2010_state_rate'].rank(method='max', ascending=False)\n",
        "\n",
        "#pull ranks into separate dataframe\n",
        "state_ranks = states[['State', '2020_rank', '2010_rank']].sort_values(by='2020_rank')\n",
        "\n",
        "#show change in rank from 2010 to 2020\n",
        "#negative number means a state has a lower 2020 response rate and has gone down in rankings\n",
        "state_ranks['rank_change'] = state_ranks['2010_rank'] - state_ranks['2020_rank']\n",
        "#state_ranks.sort_values(by='rank_change', ascending=True)\n",
        "\n",
        "#see how many states only changed 2 or fewer positions\n",
        "#small_change = state_ranks[state_ranks.rank_change.between(-2, 2, inclusive=True)].sort_values(by='rank_change')\n",
        "#small_change\n",
        "#16 states have stayed ~similar in the rankings, and this seems to impact\n",
        "#states with both high and low response rates\n",
        "#small_change.mean(axis=0)['2020_rank']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjhY7qa-UCO",
        "colab_type": "text"
      },
      "source": [
        "### Internet Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbOu9mByHce0",
        "colab_type": "text"
      },
      "source": [
        "Internet usage is only available for 2020 rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7DBXHjYM-Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Percent of response rate not from internet\n",
        "\n",
        "states2020.sort_values(by='state_not_int_pct', ascending=False)\n",
        "print(\n",
        "    \"The average state response rate to the census NOT conducted online:\",\n",
        "    states2020.mean(axis=0)['state_not_int_pct'], \"/n\",\n",
        "    states2020.mean(axis=0)['state_not_int']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c4Kc5YV4oZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average non internet response rate\n",
        "states2020.groupby(by='State').mean().sort_values(by='state_internet', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1moWoRN4oZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# highest non-internet response rate (not_int)\n",
        "states2020.sort_values(by='state_not_int', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajtMfXEB4oZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['state_not_int']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5-66yFC4oZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['state_internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rS4qL6f4oZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['2020_state_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZPt0jX4oZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Without Puerto Rico\n",
        "\n",
        "#make non-pr df\n",
        "no_pr = states2020[states2020['State'] != 'Puerto Rico']\n",
        "\n",
        "# average internet response\n",
        "no_pr.mean(axis=0)['state_internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Qif8pR4oZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average overall response rate\n",
        "no_pr.mean(axis=0)['2020_state_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tN9xyjpHg9t",
        "colab_type": "text"
      },
      "source": [
        "### Region Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWUbAvs4oZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average by region\n",
        "# NOTE as tribal tracts are not assigned to a state they do not have a corresponding region and thus are not counted in the regional calculations\n",
        "states.groupby('Region').mean().sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AggzDxDA4oZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference as of 6/15/20\n",
        "#this can take a while to run so is commented out unless needed\n",
        "#tracts.mean(axis=0)['10_20_tract_difference']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZmwRdx4oaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference by region\n",
        "tracts.groupby('Region').mean().sort_values(by='10_20_tract_difference', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qug7mLZl-rCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tract average differences vs state rates\n",
        "tracts.groupby('State').mean().sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmLScMTr4oZQ",
        "colab_type": "text"
      },
      "source": [
        "### Tribal tracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSdZysHS4oZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create df with response rates in tribal tracts\n",
        "tribal = tracts2020[tracts2020['Geo_Type'].str.contains(\"Tribal\")].sort_values(\n",
        "    by='2020_tract_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVcFRIn4oZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### tribal areas and tracts stats\n",
        "\n",
        "#mean non internet response\n",
        "tribal.mean(axis=0)['tract_not_int'] #8.37%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjVmQ5e_4oZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean internet response rate\n",
        "tribal.mean(axis=0)['internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euvyx-gL4oZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean overall response rate\n",
        "tribal.mean(axis=0)['2020_tract_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5b3R3834oZb",
        "colab_type": "text"
      },
      "source": [
        "### Tracts with 0 overall response rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eukXYcJx4oZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Tracts with 0 cumulative response rate\n",
        "is_zero = df['2020_tract_rate'] == 0\n",
        "zeros = df[is_zero]\n",
        "\n",
        "print(\n",
        "    \"Number of tracts with 0 cumulative response rate:\", len(zeros), \"\\n\"\n",
        "    )\n",
        "\n",
        "#return data frame with each tract with 0 2020 response rate\n",
        "zeros.sort_values(by='State')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Iyd3Sgp3qM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make dataframe of states with # tracts with 0%, number total tracts,\n",
        "#and what % of total tracts are 0\n",
        "temp = pd.merge(pd.DataFrame(zeros['State'].value_counts()),\n",
        "                pd.DataFrame(tracts['State'].value_counts()),\n",
        "                right_index=True, left_index=True).rename(\n",
        "                    columns={\"State_x\": \"0_tracts\", \"State_y\" : \"total_tracts\"})\n",
        "#compute percentage\n",
        "temp['0_percent'] = temp['0_tracts'] * 100 / temp['total_tracts']\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPFHo4nO4oaU",
        "colab_type": "text"
      },
      "source": [
        "## Regressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn2rfAXWrfBe",
        "colab_type": "text"
      },
      "source": [
        "### With Puerto Rico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKBskyL7s-xu",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyxyu5mbfpdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop na rows for regression\n",
        "reg_df = df.dropna(axis=0, how='any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvMEApvH9GRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(variables20.dtypes)\n",
        "variables20.info()\n",
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SHooFoBrrYEc",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = reg_df[['2010_tract_rate', '2010_state_rate',\n",
        " 'total_population', 'median_age', 'white_pct', 'black_pct', 'native_pct', \n",
        " 'asian_pct', 'pacific_pct', 'other_pct', 'two_pct', 'latino_pct', \n",
        " 'notLatino_pct', 'house_units', 'occupied_pct', 'vacant_pct', 'house_pct', \n",
        " 'bigapt_pct', 'mobilehome_pct', 'owner_pct', 'renter_pct', 'no_telephone_pct',\n",
        " 'median_value', 'rent_more_35_pct', 'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = reg_df[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "print(model20.summary())\n",
        "\n",
        "np.asarray(variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1iFVJNP8c5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(variables20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cbIp7LrSrYEg",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PToZ-lAorYEh"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R_dZfFsOrYEi",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "print(norm_model20.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fuv49LFwrYEk",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ECGhvxrhrYEl"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPMtG8ozrYEm",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = reg_df[['total_population', 'median_age', 'white_pct', \n",
        "                      'black_pct', 'native_pct','asian_pct', 'pacific_pct', \n",
        "                      'other_pct', 'two_pct', 'latino_pct', 'notLatino_pct', \n",
        "                      'house_units', 'occupied_pct', 'vacant_pct', 'house_pct', \n",
        "                      'bigapt_pct', 'mobilehome_pct', 'owner_pct', 'renter_pct', \n",
        "                      'no_telephone_pct', 'median_value', 'rent_more_35_pct', \n",
        "                      'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = reg_df[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "print(model10.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v_9tWG5drYEp",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "43-byZJzrYEq"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4bR0BjIrYEr",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "print(norm_model10.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ro4o8GDNrYEs",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXjoZqoZubCg",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "co5U07EArYEu",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = reg_df[['2010_tract_rate', '2010_state_rate',\n",
        " 'total_population', 'median_age', 'white_pct', 'black_pct', 'native_pct', \n",
        " 'asian_pct', 'pacific_pct', 'other_pct', 'two_pct', 'latino_pct', \n",
        " 'notLatino_pct', 'house_units', 'occupied_pct', 'vacant_pct', 'house_pct', \n",
        " 'bigapt_pct', 'mobilehome_pct', 'owner_pct', 'renter_pct', 'no_telephone_pct',\n",
        " 'median_value', 'rent_more_35_pct', 'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = reg_df[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "print(model_ed.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lm1iHnSurYEw",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Okny5FRDrYEx",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "print(norm_model_ed.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nccgx89crqt4",
        "colab_type": "text"
      },
      "source": [
        "### Without Puerto Rico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbsOPCbT4oaU",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd46DCij4oaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "#df without puerto rico for regression \n",
        "no_pr = reg_df[reg_df['Region'] != 'Puerto Rico']\n",
        "#this is different from earlier code no_pr = states[states.State != 'Puerto Rico']\n",
        "#earlier code omitted Puerto Rico from state level data. this eliminates from tract level data\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = no_pr[['2010_tract_rate', '2010_state_rate',\n",
        " 'total_population', 'median_age', 'white_pct', 'black_pct', 'native_pct', \n",
        " 'asian_pct', 'pacific_pct', 'other_pct', 'two_pct', 'latino_pct', \n",
        " 'notLatino_pct', 'house_units', 'occupied_pct', 'vacant_pct', 'house_pct', \n",
        " 'bigapt_pct', 'mobilehome_pct', 'owner_pct', 'renter_pct', 'no_telephone_pct',\n",
        " 'median_value', 'rent_more_35_pct', 'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = no_pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZthvp0R4oaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], \n",
        "                                                            target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', \n",
        "                                        'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0npA7T4oaZ",
        "colab_type": "text"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85hPJc_O4oaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "norm_model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQfOymD4oab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', \n",
        "                                             'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29JVbcP4oad",
        "colab_type": "text"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xixKDYjY4oad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = no_pr[['total_population', 'median_age', 'white_pct', \n",
        "                     'black_pct', 'native_pct', 'asian_pct', 'pacific_pct',\n",
        "                     'other_pct', 'two_pct', 'latino_pct', 'notLatino_pct',\n",
        "                     'house_units', 'occupied_pct', 'vacant_pct', 'house_pct',\n",
        "                     'bigapt_pct', 'mobilehome_pct', 'owner_pct', 'renter_pct',\n",
        "                     'no_telephone_pct', 'median_value', 'rent_more_35_pct',\n",
        "                     'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = no_pr[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfY5LKEc4oag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', \n",
        "                                        'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3fc89-J4oaj",
        "colab_type": "text"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlwfXss24oaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (\n",
        "    variables10.max() - variables10.min()\n",
        "    )\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "norm_model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM2yaM3d4oal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', \n",
        "                                             'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhxSdjQsFBs",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKbhPPF44oao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = no_pr[['total_population', 'median_age', 'white_pct', \n",
        "                      'black_pct', 'native_pct', 'asian_pct', 'pacific_pct', \n",
        "                      'other_pct', 'two_pct', 'latino_pct', 'notLatino_pct',\n",
        "                      'house_units', 'occupied_pct', 'vacant_pct', 'house_pct', \n",
        "                      'bigapt_pct', 'mobilehome_pct', 'owner_pct', 'renter_pct', \n",
        "                      'no_telephone_pct', 'median_value', 'rent_more_35_pct',\n",
        "                      'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = no_pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_WySxM4oaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', \n",
        "                                         'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceNe_aTSasfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "norm_model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfVDv7agtnz_",
        "colab_type": "text"
      },
      "source": [
        "### Puerto Rico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1AaDVLtr9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create df with just puerto rico\n",
        "pr = reg_df[reg_df['Region'] == 'Puerto Rico']\n",
        "pr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tYdF-C1cu1y8"
      },
      "source": [
        "#### 2020 regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RlidAAwwu1y-",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = pr[['2010_tract_rate', 'total_population', 'median_age', \n",
        "                  'white_pct', 'black_pct', 'native_pct', 'asian_pct',\n",
        "                  'pacific_pct', 'other_pct', 'two_pct', 'latino_pct',  \n",
        "                  'notLatino_pct', 'house_units', 'occupied_pct', 'vacant_pct',\n",
        "                  'house_pct', 'bigapt_pct', 'mobilehome_pct', 'owner_pct',\n",
        "                  'renter_pct', 'no_telephone_pct', 'median_value',\n",
        "                  'rent_more_35_pct', 'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cvkw34rku1zA",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, \n",
        "                 regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', \n",
        "                                        'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JVacRXRu1zB"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5KAHuRvHu1zC",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "norm_model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2jTl88Abu1zE",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', \n",
        "                                             'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eBcoXR_Iu1zG"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRFQpznKu1zG",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = pr[['total_population', 'median_age',\n",
        "                  'white_pct', 'black_pct', 'native_pct', 'asian_pct',\n",
        "                  'pacific_pct', 'other_pct', 'two_pct', 'latino_pct', \n",
        "                  'notLatino_pct', 'house_units', 'occupied_pct', 'vacant_pct',\n",
        "                  'house_pct', 'bigapt_pct', 'mobilehome_pct', 'owner_pct',\n",
        "                  'renter_pct', 'no_telephone_pct', 'median_value',\n",
        "                  'rent_more_35_pct', 'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = pr[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6CS4y7X_u1zI",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', \n",
        "                                        'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-pAJMVeu1zK"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BtAXZ8Zeu1zK",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "norm_model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wxTWDr54u1zM",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', \n",
        "                                             'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KsqdFNHru1zN"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnSLhYOwu1zN",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = pr[['2010_tract_rate', 'total_population', 'median_age',\n",
        "                   'white_pct', 'black_pct', 'native_pct', 'asian_pct',\n",
        "                   'pacific_pct', 'other_pct', 'two_pct', 'latino_pct', \n",
        "                   'notLatino_pct', 'house_units', 'occupied_pct', 'vacant_pct',\n",
        "                   'house_pct', 'bigapt_pct', 'mobilehome_pct', 'owner_pct',\n",
        "                   'renter_pct', 'no_telephone_pct', 'median_value',\n",
        "                   'rent_more_35_pct', 'median_income', 'no_int_pct']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAFrD4JRu1zQ",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', \n",
        "                                         'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QGqYmMH6u1zS",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "norm_model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}