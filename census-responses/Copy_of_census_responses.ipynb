{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of census-responses.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0TAdi8gb4oZK",
        "WAjhY7qa-UCO",
        "2tN9xyjpHg9t",
        "kmLScMTr4oZQ",
        "S5b3R3834oZb",
        "Tn2rfAXWrfBe",
        "aKBskyL7s-xu",
        "PToZ-lAorYEh",
        "ECGhvxrhrYEl",
        "43-byZJzrYEq",
        "mXjoZqoZubCg",
        "Nccgx89crqt4",
        "tbsOPCbT4oaU",
        "mL0npA7T4oaZ",
        "c29JVbcP4oad",
        "h3fc89-J4oaj",
        "twhxSdjQsFBs",
        "CfVDv7agtnz_",
        "tYdF-C1cu1y8",
        "7JVacRXRu1zB",
        "eBcoXR_Iu1zG",
        "c-pAJMVeu1zK",
        "KsqdFNHru1zN"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdiffendal/USAT/blob/master/census-responses/Copy_of_census_responses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbXbhig24oZG",
        "colab_type": "text"
      },
      "source": [
        "# 2020 Census Response Rate Analysis\n",
        "\n",
        "### Theresa Diffendal, USA Today data intern, 06/2020\n",
        "\n",
        "#### 2020 response rates from: https://2020census.gov/en/response-rates.html\n",
        "#### 2010 response rates from: https://api.census.gov/data/2010/dec/responserate/variables.html\n",
        "#### Demographic information in 2014-2018 ACS 5-year-estimate from: https://data2.nhgis.org/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TAdi8gb4oZK",
        "colab_type": "text"
      },
      "source": [
        "## Column Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dWSiayi_y6Z",
        "colab_type": "text"
      },
      "source": [
        "GEO_ID = Geographic Identifier\n",
        "\n",
        "RESP_DATE = Posting Date\n",
        "\n",
        "State = name of state (one of the 50 states, District of Columbia, Puerto Rico, or NaN)\n",
        "\n",
        "Geo_Name = name of the tract, county, state\n",
        "\n",
        "Region = region of the U.S. in which state is located as defined by census map at https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
        "\n",
        "Geo_Type = type of geography; possible answers include Census Tract, Congressional District, Consolidated City, Country, County, County Subdivision, Place, Region, State, Tribal Tract, Tribal Area\n",
        "\n",
        "DRRINT = Daily Self-Response Rate - Internet\n",
        "\n",
        "DRRALL = Daily Self-Response Rate – Overall\n",
        "\n",
        "CRRINT = Cumulative Self-Response Rate - Internet; renamed internet\n",
        "\n",
        "not_int = new calculated column showing response rate NOT from internet\n",
        "\n",
        "CRRALL = Cumulative Self-Response Rate – Overall; renamed 2020_rate\n",
        "\n",
        "DINTMIN = Minimum Daily Internet Self-Response Rate\n",
        "\n",
        "DMIN = Minimum Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMIN = Minimum Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMIN = Minimum Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTMAX = Maximum Daily Internet Self-Response Rate\n",
        "\n",
        "DMAX = Maximum Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMAX = Maximum Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMAX = Maximum Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTAVG = Average Daily Internet Self-Response Rate\n",
        "\n",
        "DAVG = Average Daily Overall Self-Response Rate\n",
        "\n",
        "CINTAVG = Average Cumulative Internet Self-Response Rate\n",
        "\n",
        "CAVG = Average Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTMED = Median Daily Internet Self-Response Rate\n",
        "\n",
        "DMED = Median Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMED = Median Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMED = Median Cumulative Overall Self-Response Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxd7lfhbqD3W",
        "colab_type": "text"
      },
      "source": [
        "## Read, Merge, Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDwZx7aHAWpf",
        "colab_type": "text"
      },
      "source": [
        "### Initial Load and Merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip_J3r424oZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "6d883ae0-0e29-46d8-81b8-c0bafed914f8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in 2020 response rates\n",
        "initial_df = pd.read_csv('https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/decennialrr2020.csv')\n",
        "# had to download from https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/ resave as UTF-8 CSV, hence the 2\n",
        "crosswalk = pd.read_csv('https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/decennialrr2020_crosswalkfile.csv', encoding='latin-1')\n",
        "# states paired with region as defined by census map at https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
        "regions = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/state_region.csv')\n",
        "\n",
        "# merge responses and crosswalk\n",
        "temp = pd.merge(initial_df, crosswalk, on='GEO_ID')\n",
        "\n",
        "#merge merged1 with region data\n",
        "merged = pd.merge(temp, regions, on='State')\n",
        "\n",
        "# create column showing responses not from internet\n",
        "merged['not_int'] = merged.CRRALL - merged.CRRINT\n",
        "merged['not_int_pct'] = (merged.not_int) * 100 / merged.CRRALL\n",
        "\n",
        "#reorder columns to move State, Geo_Name and Geo_Type to front; also going to drop some values\n",
        "cols = merged.columns.tolist()\n",
        "cols = ['GEO_ID', 'RESP_DATE', 'State', 'Geo_Name', 'Region', 'Geo_Type', \n",
        "        'CRRINT', 'not_int', 'not_int_pct', 'CRRALL']\n",
        "merged = merged[cols]\n",
        "merged = merged.rename(columns={'CRRINT':'internet', 'CRRALL':'2020_rate'})\n",
        "merged"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GEO_ID</th>\n",
              "      <th>RESP_DATE</th>\n",
              "      <th>State</th>\n",
              "      <th>Geo_Name</th>\n",
              "      <th>Region</th>\n",
              "      <th>Geo_Type</th>\n",
              "      <th>internet</th>\n",
              "      <th>not_int</th>\n",
              "      <th>not_int_pct</th>\n",
              "      <th>2020_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0100000US</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United States</td>\n",
              "      <td>na</td>\n",
              "      <td>Country</td>\n",
              "      <td>49.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>20.226537</td>\n",
              "      <td>61.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0200000US1</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>na</td>\n",
              "      <td>Region</td>\n",
              "      <td>49.5</td>\n",
              "      <td>11.8</td>\n",
              "      <td>19.249592</td>\n",
              "      <td>61.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0200000US2</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>na</td>\n",
              "      <td>Region</td>\n",
              "      <td>53.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>20.658683</td>\n",
              "      <td>66.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0200000US3</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>South</td>\n",
              "      <td>na</td>\n",
              "      <td>Region</td>\n",
              "      <td>45.6</td>\n",
              "      <td>13.3</td>\n",
              "      <td>22.580645</td>\n",
              "      <td>58.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0200000US4</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>West</td>\n",
              "      <td>na</td>\n",
              "      <td>Region</td>\n",
              "      <td>52.3</td>\n",
              "      <td>10.1</td>\n",
              "      <td>16.185897</td>\n",
              "      <td>62.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123245</th>\n",
              "      <td>1400000US72153750502</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Tract 7505.02, Yauco</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>22.8</td>\n",
              "      <td>16.4</td>\n",
              "      <td>41.836735</td>\n",
              "      <td>39.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123246</th>\n",
              "      <td>1400000US72153750503</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Tract 7505.03, Yauco</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>12.1</td>\n",
              "      <td>13.8</td>\n",
              "      <td>53.281853</td>\n",
              "      <td>25.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123247</th>\n",
              "      <td>1400000US72153750601</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Tract 7506.01, Yauco</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>14.3</td>\n",
              "      <td>12.7</td>\n",
              "      <td>47.037037</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123248</th>\n",
              "      <td>1400000US72153750602</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Tract 7506.02, Yauco</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>6.4</td>\n",
              "      <td>11.8</td>\n",
              "      <td>64.835165</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123249</th>\n",
              "      <td>5001600US7298</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Resident Commissioner District (at Large)</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Congressional District</td>\n",
              "      <td>11.4</td>\n",
              "      <td>11.2</td>\n",
              "      <td>49.557522</td>\n",
              "      <td>22.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123250 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      GEO_ID   RESP_DATE  ... not_int_pct 2020_rate\n",
              "0                  0100000US  2020-06-30  ...   20.226537      61.8\n",
              "1                 0200000US1  2020-06-30  ...   19.249592      61.3\n",
              "2                 0200000US2  2020-06-30  ...   20.658683      66.8\n",
              "3                 0200000US3  2020-06-30  ...   22.580645      58.9\n",
              "4                 0200000US4  2020-06-30  ...   16.185897      62.4\n",
              "...                      ...         ...  ...         ...       ...\n",
              "123245  1400000US72153750502  2020-06-30  ...   41.836735      39.2\n",
              "123246  1400000US72153750503  2020-06-30  ...   53.281853      25.9\n",
              "123247  1400000US72153750601  2020-06-30  ...   47.037037      27.0\n",
              "123248  1400000US72153750602  2020-06-30  ...   64.835165      18.2\n",
              "123249         5001600US7298  2020-06-30  ...   49.557522      22.6\n",
              "\n",
              "[123250 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppli4PGC4oZd",
        "colab_type": "text"
      },
      "source": [
        "### States"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxWiGJyALk8C",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxRHegvy4oZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create df with response rate by state\n",
        "states2020 = merged[merged['Geo_Type'] == 'State']\n",
        "states2020 = states2020.rename(columns={\"internet\": \"state_internet\", \n",
        "                                        \"not_int\" : \"state_not_int\", \n",
        "                                        'not_int_pct' : 'state_not_int_pct',\n",
        "                                        \"2020_rate\" : \"2020_state_rate\"})\n",
        "\n",
        "# print df and sort by highest cumulative response rate\n",
        "#states2020.sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDPo55jgLtGy",
        "colab_type": "text"
      },
      "source": [
        "#### Join 2010 states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HDvnJhF4oaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "29772c68-853a-461b-cfc8-ff424967e533"
      },
      "source": [
        "# read in csvs with 2010 response data for states\n",
        "states2010 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/states2010.csv')\n",
        "\n",
        "# merge with 2020 states\n",
        "states = pd.merge(states2020, states2010, on='State')\n",
        "#get the column names\n",
        "cols = states.columns.tolist()\n",
        "#only select columns we want\n",
        "cols = ['GEO_ID', 'State', 'Region',\n",
        " '2020_state_rate', '2010_rate', '2000_rate']\n",
        "states = states[cols]\n",
        "states = states.rename(columns={'2000_rate':'2000_state_rate', '2010_rate':'2010_state_rate'})\n",
        "\n",
        "#create column with difference in 2010 vs 2020 response rate\n",
        "states['10_20_state_difference'] = (states['2020_state_rate'] - states['2010_state_rate']) * 100 / states['2010_state_rate']\n",
        "\n",
        "#print table sorted by 10-20 difference largest ---> smallest\n",
        "states.sort_values(by=['2000_state_rate'], ascending=True)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GEO_ID</th>\n",
              "      <th>State</th>\n",
              "      <th>Region</th>\n",
              "      <th>2020_state_rate</th>\n",
              "      <th>2010_state_rate</th>\n",
              "      <th>2000_state_rate</th>\n",
              "      <th>10_20_state_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0400000US72</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>22.6</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>-58.148148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0400000US15</td>\n",
              "      <td>Hawaii</td>\n",
              "      <td>West</td>\n",
              "      <td>58.0</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>-14.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0400000US02</td>\n",
              "      <td>Alaska</td>\n",
              "      <td>West</td>\n",
              "      <td>47.8</td>\n",
              "      <td>64</td>\n",
              "      <td>67</td>\n",
              "      <td>-25.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0400000US23</td>\n",
              "      <td>Maine</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>53.3</td>\n",
              "      <td>68</td>\n",
              "      <td>67</td>\n",
              "      <td>-21.617647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0400000US54</td>\n",
              "      <td>West Virginia</td>\n",
              "      <td>South</td>\n",
              "      <td>53.4</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>-17.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0400000US50</td>\n",
              "      <td>Vermont</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>55.1</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>-20.144928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0400000US45</td>\n",
              "      <td>South Carolina</td>\n",
              "      <td>South</td>\n",
              "      <td>56.3</td>\n",
              "      <td>75</td>\n",
              "      <td>68</td>\n",
              "      <td>-24.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0400000US35</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>West</td>\n",
              "      <td>50.9</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>-21.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0400000US22</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>South</td>\n",
              "      <td>56.0</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>-13.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0400000US01</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>South</td>\n",
              "      <td>59.5</td>\n",
              "      <td>72</td>\n",
              "      <td>68</td>\n",
              "      <td>-17.361111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0400000US36</td>\n",
              "      <td>New York</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>57.3</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>-16.956522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0400000US11</td>\n",
              "      <td>District of Columbia</td>\n",
              "      <td>South</td>\n",
              "      <td>57.9</td>\n",
              "      <td>72</td>\n",
              "      <td>69</td>\n",
              "      <td>-19.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0400000US37</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>South</td>\n",
              "      <td>58.0</td>\n",
              "      <td>76</td>\n",
              "      <td>69</td>\n",
              "      <td>-23.684211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0400000US04</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>West</td>\n",
              "      <td>58.4</td>\n",
              "      <td>69</td>\n",
              "      <td>70</td>\n",
              "      <td>-15.362319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0400000US05</td>\n",
              "      <td>Arkansas</td>\n",
              "      <td>South</td>\n",
              "      <td>56.6</td>\n",
              "      <td>69</td>\n",
              "      <td>70</td>\n",
              "      <td>-17.971014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0400000US48</td>\n",
              "      <td>Texas</td>\n",
              "      <td>South</td>\n",
              "      <td>56.6</td>\n",
              "      <td>71</td>\n",
              "      <td>70</td>\n",
              "      <td>-20.281690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0400000US28</td>\n",
              "      <td>Mississippi</td>\n",
              "      <td>South</td>\n",
              "      <td>56.8</td>\n",
              "      <td>69</td>\n",
              "      <td>70</td>\n",
              "      <td>-17.681159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0400000US12</td>\n",
              "      <td>Florida</td>\n",
              "      <td>South</td>\n",
              "      <td>58.9</td>\n",
              "      <td>74</td>\n",
              "      <td>71</td>\n",
              "      <td>-20.405405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0400000US32</td>\n",
              "      <td>Nevada</td>\n",
              "      <td>West</td>\n",
              "      <td>61.1</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>-13.943662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0400000US10</td>\n",
              "      <td>Delaware</td>\n",
              "      <td>South</td>\n",
              "      <td>59.6</td>\n",
              "      <td>72</td>\n",
              "      <td>71</td>\n",
              "      <td>-17.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0400000US40</td>\n",
              "      <td>Oklahoma</td>\n",
              "      <td>South</td>\n",
              "      <td>56.2</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>-17.352941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0400000US30</td>\n",
              "      <td>Montana</td>\n",
              "      <td>West</td>\n",
              "      <td>55.5</td>\n",
              "      <td>68</td>\n",
              "      <td>72</td>\n",
              "      <td>-18.382353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0400000US13</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>South</td>\n",
              "      <td>57.7</td>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>-19.861111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0400000US47</td>\n",
              "      <td>Tennessee</td>\n",
              "      <td>South</td>\n",
              "      <td>61.3</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "      <td>-19.342105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0400000US21</td>\n",
              "      <td>Kentucky</td>\n",
              "      <td>South</td>\n",
              "      <td>65.3</td>\n",
              "      <td>77</td>\n",
              "      <td>72</td>\n",
              "      <td>-15.194805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0400000US44</td>\n",
              "      <td>Rhode Island</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>59.7</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>-18.219178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0400000US49</td>\n",
              "      <td>Utah</td>\n",
              "      <td>West</td>\n",
              "      <td>66.1</td>\n",
              "      <td>75</td>\n",
              "      <td>74</td>\n",
              "      <td>-11.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0400000US33</td>\n",
              "      <td>New Hampshire</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>61.7</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>-15.479452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0400000US08</td>\n",
              "      <td>Colorado</td>\n",
              "      <td>West</td>\n",
              "      <td>65.1</td>\n",
              "      <td>72</td>\n",
              "      <td>75</td>\n",
              "      <td>-9.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0400000US56</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>West</td>\n",
              "      <td>55.9</td>\n",
              "      <td>69</td>\n",
              "      <td>75</td>\n",
              "      <td>-18.985507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0400000US53</td>\n",
              "      <td>Washington</td>\n",
              "      <td>West</td>\n",
              "      <td>67.2</td>\n",
              "      <td>76</td>\n",
              "      <td>75</td>\n",
              "      <td>-11.578947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0400000US51</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>South</td>\n",
              "      <td>66.6</td>\n",
              "      <td>78</td>\n",
              "      <td>76</td>\n",
              "      <td>-14.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0400000US06</td>\n",
              "      <td>California</td>\n",
              "      <td>West</td>\n",
              "      <td>62.9</td>\n",
              "      <td>73</td>\n",
              "      <td>76</td>\n",
              "      <td>-13.835616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0400000US34</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>63.8</td>\n",
              "      <td>74</td>\n",
              "      <td>76</td>\n",
              "      <td>-13.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0400000US24</td>\n",
              "      <td>Maryland</td>\n",
              "      <td>South</td>\n",
              "      <td>65.8</td>\n",
              "      <td>76</td>\n",
              "      <td>76</td>\n",
              "      <td>-13.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0400000US17</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>66.5</td>\n",
              "      <td>76</td>\n",
              "      <td>76</td>\n",
              "      <td>-12.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0400000US25</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>63.8</td>\n",
              "      <td>75</td>\n",
              "      <td>76</td>\n",
              "      <td>-14.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0400000US29</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>61.9</td>\n",
              "      <td>74</td>\n",
              "      <td>76</td>\n",
              "      <td>-16.351351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0400000US16</td>\n",
              "      <td>Idaho</td>\n",
              "      <td>West</td>\n",
              "      <td>65.3</td>\n",
              "      <td>76</td>\n",
              "      <td>77</td>\n",
              "      <td>-14.078947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0400000US41</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>West</td>\n",
              "      <td>64.2</td>\n",
              "      <td>76</td>\n",
              "      <td>77</td>\n",
              "      <td>-15.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0400000US42</td>\n",
              "      <td>Pennsylvania</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>65.0</td>\n",
              "      <td>77</td>\n",
              "      <td>78</td>\n",
              "      <td>-15.584416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0400000US09</td>\n",
              "      <td>Connecticut</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>65.2</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>-14.210526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0400000US20</td>\n",
              "      <td>Kansas</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>65.6</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>-13.684211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0400000US38</td>\n",
              "      <td>North Dakota</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>61.5</td>\n",
              "      <td>74</td>\n",
              "      <td>78</td>\n",
              "      <td>-16.891892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0400000US26</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>68.0</td>\n",
              "      <td>78</td>\n",
              "      <td>79</td>\n",
              "      <td>-12.820513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0400000US18</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>66.2</td>\n",
              "      <td>79</td>\n",
              "      <td>79</td>\n",
              "      <td>-16.202532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0400000US39</td>\n",
              "      <td>Ohio</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>66.4</td>\n",
              "      <td>78</td>\n",
              "      <td>79</td>\n",
              "      <td>-14.871795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0400000US46</td>\n",
              "      <td>South Dakota</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>63.0</td>\n",
              "      <td>76</td>\n",
              "      <td>80</td>\n",
              "      <td>-17.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0400000US27</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>71.3</td>\n",
              "      <td>81</td>\n",
              "      <td>81</td>\n",
              "      <td>-11.975309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0400000US31</td>\n",
              "      <td>Nebraska</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>67.9</td>\n",
              "      <td>77</td>\n",
              "      <td>81</td>\n",
              "      <td>-11.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0400000US19</td>\n",
              "      <td>Iowa</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>67.9</td>\n",
              "      <td>79</td>\n",
              "      <td>82</td>\n",
              "      <td>-14.050633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0400000US55</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>68.7</td>\n",
              "      <td>82</td>\n",
              "      <td>85</td>\n",
              "      <td>-16.219512</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         GEO_ID                 State  ... 2000_state_rate  10_20_state_difference\n",
              "51  0400000US72           Puerto Rico  ...              54              -58.148148\n",
              "11  0400000US15                Hawaii  ...              66              -14.705882\n",
              "1   0400000US02                Alaska  ...              67              -25.312500\n",
              "19  0400000US23                 Maine  ...              67              -21.617647\n",
              "48  0400000US54         West Virginia  ...              68              -17.846154\n",
              "45  0400000US50               Vermont  ...              68              -20.144928\n",
              "40  0400000US45        South Carolina  ...              68              -24.933333\n",
              "31  0400000US35            New Mexico  ...              68              -21.692308\n",
              "18  0400000US22             Louisiana  ...              68              -13.846154\n",
              "0   0400000US01               Alabama  ...              68              -17.361111\n",
              "32  0400000US36              New York  ...              69              -16.956522\n",
              "8   0400000US11  District of Columbia  ...              69              -19.583333\n",
              "33  0400000US37        North Carolina  ...              69              -23.684211\n",
              "2   0400000US04               Arizona  ...              70              -15.362319\n",
              "3   0400000US05              Arkansas  ...              70              -17.971014\n",
              "43  0400000US48                 Texas  ...              70              -20.281690\n",
              "24  0400000US28           Mississippi  ...              70              -17.681159\n",
              "9   0400000US12               Florida  ...              71              -20.405405\n",
              "28  0400000US32                Nevada  ...              71              -13.943662\n",
              "7   0400000US10              Delaware  ...              71              -17.222222\n",
              "36  0400000US40              Oklahoma  ...              71              -17.352941\n",
              "26  0400000US30               Montana  ...              72              -18.382353\n",
              "10  0400000US13               Georgia  ...              72              -19.861111\n",
              "42  0400000US47             Tennessee  ...              72              -19.342105\n",
              "17  0400000US21              Kentucky  ...              72              -15.194805\n",
              "39  0400000US44          Rhode Island  ...              73              -18.219178\n",
              "44  0400000US49                  Utah  ...              74              -11.866667\n",
              "29  0400000US33         New Hampshire  ...              74              -15.479452\n",
              "5   0400000US08              Colorado  ...              75               -9.583333\n",
              "50  0400000US56               Wyoming  ...              75              -18.985507\n",
              "47  0400000US53            Washington  ...              75              -11.578947\n",
              "46  0400000US51              Virginia  ...              76              -14.615385\n",
              "4   0400000US06            California  ...              76              -13.835616\n",
              "30  0400000US34            New Jersey  ...              76              -13.783784\n",
              "20  0400000US24              Maryland  ...              76              -13.421053\n",
              "13  0400000US17              Illinois  ...              76              -12.500000\n",
              "21  0400000US25         Massachusetts  ...              76              -14.933333\n",
              "25  0400000US29              Missouri  ...              76              -16.351351\n",
              "12  0400000US16                 Idaho  ...              77              -14.078947\n",
              "37  0400000US41                Oregon  ...              77              -15.526316\n",
              "38  0400000US42          Pennsylvania  ...              78              -15.584416\n",
              "6   0400000US09           Connecticut  ...              78              -14.210526\n",
              "16  0400000US20                Kansas  ...              78              -13.684211\n",
              "34  0400000US38          North Dakota  ...              78              -16.891892\n",
              "22  0400000US26              Michigan  ...              79              -12.820513\n",
              "14  0400000US18               Indiana  ...              79              -16.202532\n",
              "35  0400000US39                  Ohio  ...              79              -14.871795\n",
              "41  0400000US46          South Dakota  ...              80              -17.105263\n",
              "23  0400000US27             Minnesota  ...              81              -11.975309\n",
              "27  0400000US31              Nebraska  ...              81              -11.818182\n",
              "15  0400000US19                  Iowa  ...              82              -14.050633\n",
              "49  0400000US55             Wisconsin  ...              85              -16.219512\n",
              "\n",
              "[52 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG6fiKIZp8eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print above dataframe to csv\n",
        "#from google.colab import drive\n",
        "#drive.mount('/gdrive')\n",
        "#4/1QHjzPlDYwEyGbg5xGgBbeLxQRP_D-nPkF9bC8U5zL5ShJLIeEW_UiE\n",
        "states.to_csv('/gdrive/My Drive/0USA Today/state_rates.csv')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QutNTWkb4oZN",
        "colab_type": "text"
      },
      "source": [
        "### Census Tracts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYFZkXWy_ehB",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Tracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "poLTe8ZR4oZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9f92bea8-5474-41b8-8420-9a23e67290ba"
      },
      "source": [
        "# select just census tract geo types\n",
        "tracts2020 = merged[merged['Geo_Type'].str.contains(\"Tract\")]\n",
        "#rename column\n",
        "tracts2020 = tracts2020.rename(columns={\"2020_rate\": \"2020_tract_rate\",\n",
        "                                        'not_int':'tract_not_int',\n",
        "                                        'not_int_pct':'tract_not_int_pct'})\n",
        "# sort by highest cumulative response rate\n",
        "tracts2020.sort_values(by='2020_tract_rate', ascending=False)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GEO_ID</th>\n",
              "      <th>RESP_DATE</th>\n",
              "      <th>State</th>\n",
              "      <th>Geo_Name</th>\n",
              "      <th>Region</th>\n",
              "      <th>Geo_Type</th>\n",
              "      <th>internet</th>\n",
              "      <th>tract_not_int</th>\n",
              "      <th>tract_not_int_pct</th>\n",
              "      <th>2020_tract_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27200</th>\n",
              "      <td>1400000US13215010606</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>Tract 106.06, Muscogee</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.1</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50423</th>\n",
              "      <td>1400000US25013812903</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Tract 8129.03, Hampden</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>86.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.411386</td>\n",
              "      <td>93.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54026</th>\n",
              "      <td>1400000US26099223801</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>Tract 2238.01, Macomb</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>86.4</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7.096774</td>\n",
              "      <td>93.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54838</th>\n",
              "      <td>1400000US26139021605</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>Tract 216.05, Ottawa</td>\n",
              "      <td>Midwest</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>85.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.551241</td>\n",
              "      <td>92.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113809</th>\n",
              "      <td>1400000US51059492202</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Tract 4922.02, Fairfax</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>89.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.667745</td>\n",
              "      <td>92.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89622</th>\n",
              "      <td>1400000US40109980003</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Oklahoma</td>\n",
              "      <td>Tract 9800.03, Oklahoma</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46742</th>\n",
              "      <td>1400000US22125951703</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>Tract 9517.03, West Feliciana</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94380</th>\n",
              "      <td>1400000US42019980100</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Pennsylvania</td>\n",
              "      <td>Tract 9801, Butler</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89623</th>\n",
              "      <td>1400000US40109980005</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>Oklahoma</td>\n",
              "      <td>Tract 9800.05, Oklahoma</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73868</th>\n",
              "      <td>1400000US36047005303</td>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>New York</td>\n",
              "      <td>Tract 53.03, Kings</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84519 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      GEO_ID   RESP_DATE  ... tract_not_int_pct 2020_tract_rate\n",
              "27200   1400000US13215010606  2020-06-30  ...        100.000000            98.1\n",
              "50423   1400000US25013812903  2020-06-30  ...          7.411386            93.1\n",
              "54026   1400000US26099223801  2020-06-30  ...          7.096774            93.0\n",
              "54838   1400000US26139021605  2020-06-30  ...          7.551241            92.7\n",
              "113809  1400000US51059492202  2020-06-30  ...          3.667745            92.7\n",
              "...                      ...         ...  ...               ...             ...\n",
              "89622   1400000US40109980003  2020-06-30  ...               NaN             0.0\n",
              "46742   1400000US22125951703  2020-06-30  ...               NaN             0.0\n",
              "94380   1400000US42019980100  2020-06-30  ...               NaN             0.0\n",
              "89623   1400000US40109980005  2020-06-30  ...               NaN             0.0\n",
              "73868   1400000US36047005303  2020-06-30  ...               NaN             0.0\n",
              "\n",
              "[84519 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHSpstWKIYJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e61eb50f-74c7-421a-cb0f-9a2c3e81f2d4"
      },
      "source": [
        "#tract rates compared to state averages\n",
        "tract2020states = pd.merge(tracts2020, states, on=['State', 'Region'])\n",
        "tract2020states = tract2020states[['GEO_ID_x', 'State', 'Geo_Name', 'Geo_Type', 'Region','2020_tract_rate', '2020_state_rate', '2010_state_rate', '10_20_state_difference']]\n",
        "tract2020states = tract2020states.rename(columns={'GEO_ID_x':'GEO_ID'})\n",
        "tract2020states['2020_tract_st_diff'] = tract2020states['2020_tract_rate'] - tract2020states['2020_state_rate']\n",
        "tract2020states.sort_values(by=['2020_tract_st_diff'])\n",
        "\n",
        "print(\n",
        "    \"Difference in records:\", len(tracts2020) - len(tract2020states), \"\\n\",\n",
        "    \"Number of tribal tracts:\", len(tracts2020[tracts2020['Geo_Type'].str.contains(\"Tribal\")])\n",
        ")\n",
        "#merging tracts with states will drop tribal tracts (as they have no state), so those are examined separately below"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Difference in records: 426 \n",
            " Number of tribal tracts: 426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw37IfN-MoJt",
        "colab_type": "text"
      },
      "source": [
        "#### Join 2010 tract rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzl46WTuLqog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in csvs with 2010 response data for tracts and states\n",
        "tracts2010 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/2010responserate.csv')\n",
        "#rename this column\n",
        "tracts2010 = tracts2010.rename(columns={'FSRR2010':'2010_tract_rate'})\n",
        "#tracts2010"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8wlaOo84oZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## difference in row numbers: both tract dfs have 84519 rows, but when joined only 84093\n",
        "# Identify what values are in tracts2010 and not in tracts2020\n",
        "#key_diff1 = set(tracts2010.GEO_ID).difference(tracts2020.GEO_ID)\n",
        "#len(key_diff1)\n",
        "#key_diff1\n",
        "\n",
        "# Identify what values are in tracts2020 and not in tracts2010\n",
        "#key_diff2 = set(tracts2020.GEO_ID).difference(tracts2010.GEO_ID)\n",
        "#len(key_diff2)\n",
        "#key_diff2\n",
        "\n",
        "# 2010 rates do not include the 426 tribal tracts\n",
        "# Those differences account for 426 tracts, which is .5% of the original 84519 \n",
        "# tracts. These tracts are dropped in the comparative analyses and are analyzed separately"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkzjcuo4oZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge with 2020 tracts\n",
        "tracts = pd.merge(tract2020states, tracts2010, on='GEO_ID')\n",
        "#select only columns we want\n",
        "cols = ['Geo_Name','county', 'State_y', 'Region', 'Geo_Type', '2020_tract_rate', '2010_tract_rate', '2020_tract_st_diff', '2020_state_rate', '2010_state_rate', '10_20_state_difference', 'GEO_ID']\n",
        "tracts = tracts[cols]\n",
        "#rename weird column name\n",
        "tracts = tracts.rename(columns={'State_y':'State'})\n",
        "#print df sorted largest --> smallest 2010 rate\n",
        "#tracts.sort_values(by='2010_tract_rate', ascending=False)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19V3l294oZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "outputId": "30cee114-6f77-43cd-f9c4-c6d71785a491"
      },
      "source": [
        "#how many null 2010 response values are there\n",
        "is_temp = tracts.isnull()\n",
        "no_2010 = is_temp.any(axis=1)\n",
        "no_2010 = tracts[no_2010]\n",
        "no_2010.sort_values(by=\"2010_tract_rate\")\n",
        "\n",
        "#tracts2010[tracts2010['2010_tract_rate'] == 0]\n",
        "\n",
        "print(\n",
        "    \"There are\", len(no_2010), \"null 2010 response rate values out of\", \n",
        "    len(tracts2010), \"total 2010 observations, \\n or\",\n",
        "    len(no_2010) * 100 / len(tracts2010) , \"% \\n\",\n",
        "    \"and\", len(no_2010) * 100 / len(tracts), \"% of the\", len(tracts),\n",
        "    \"total of 2020 and 2010 tracts\"\n",
        ")\n",
        "\n",
        "\n",
        "#how many 0 rate tracts in each state\n",
        "print(no_2010['State'].value_counts())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 531 null 2010 response rate values out of 84519 total 2010 observations, \n",
            " or 0.6282611010542009 % \n",
            " and 0.6314437586957298 % of the 84093 total of 2020 and 2010 tracts\n",
            " Wisconsin               92\n",
            " Florida                 56\n",
            " Texas                   54\n",
            " California              54\n",
            " New York                50\n",
            " Arizona                 50\n",
            " New Mexico              30\n",
            " Massachusetts           21\n",
            " Washington              17\n",
            " Montana                 14\n",
            " South Dakota            13\n",
            " North Carolina           8\n",
            " Alabama                  7\n",
            " Minnesota                7\n",
            " Idaho                    6\n",
            " Utah                     6\n",
            " North Dakota             6\n",
            " Colorado                 6\n",
            " Wyoming                  6\n",
            " Nevada                   3\n",
            " Vermont                  3\n",
            " Virginia                 3\n",
            " Maine                    3\n",
            " New Hampshire            3\n",
            " Oklahoma                 2\n",
            " New Jersey               2\n",
            " Nebraska                 2\n",
            " Rhode Island             1\n",
            " Alaska                   1\n",
            " District of Columbia     1\n",
            " South Carolina           1\n",
            " Tennessee                1\n",
            " Pennsylvania             1\n",
            " Delaware                 1\n",
            "Name: State, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1oLIOrq4oZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "3cc88cfa-ebee-4da2-d024-065de9ad91cb"
      },
      "source": [
        "#create column with difference in 2010 vs 2020 response rate\n",
        "tracts['10_20_tract_difference'] = (tracts['2020_tract_rate'] - tracts['2010_tract_rate']) / tracts['2010_tract_rate']\n",
        "#sort df largest --> smallest 10-20 difference\n",
        "tracts.sort_values(by='10_20_tract_difference', ascending=False)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Geo_Name</th>\n",
              "      <th>county</th>\n",
              "      <th>State</th>\n",
              "      <th>Region</th>\n",
              "      <th>Geo_Type</th>\n",
              "      <th>2020_tract_rate</th>\n",
              "      <th>2010_tract_rate</th>\n",
              "      <th>2020_tract_st_diff</th>\n",
              "      <th>2020_state_rate</th>\n",
              "      <th>2010_state_rate</th>\n",
              "      <th>10_20_state_difference</th>\n",
              "      <th>GEO_ID</th>\n",
              "      <th>10_20_tract_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12328</th>\n",
              "      <td>Tract 1103.01, Santa Cruz</td>\n",
              "      <td>Santa Cruz County</td>\n",
              "      <td>California</td>\n",
              "      <td>West</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>45.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>62.9</td>\n",
              "      <td>73</td>\n",
              "      <td>-13.835616</td>\n",
              "      <td>1400000US06087110301</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53804</th>\n",
              "      <td>Tract 1596.02, Suffolk</td>\n",
              "      <td>Suffolk County</td>\n",
              "      <td>New York</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>60.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>57.3</td>\n",
              "      <td>69</td>\n",
              "      <td>-16.956522</td>\n",
              "      <td>1400000US36103159602</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53322</th>\n",
              "      <td>Tract 605.05, Saratoga</td>\n",
              "      <td>Saratoga County</td>\n",
              "      <td>New York</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>19.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-37.9</td>\n",
              "      <td>57.3</td>\n",
              "      <td>69</td>\n",
              "      <td>-16.956522</td>\n",
              "      <td>1400000US36091060505</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53425</th>\n",
              "      <td>Tract 7403, Schoharie</td>\n",
              "      <td>Schoharie County</td>\n",
              "      <td>New York</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>8.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-49.0</td>\n",
              "      <td>57.3</td>\n",
              "      <td>69</td>\n",
              "      <td>-16.956522</td>\n",
              "      <td>1400000US36095740300</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21943</th>\n",
              "      <td>Tract 231.15, DeKalb</td>\n",
              "      <td>DeKalb County</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-47.7</td>\n",
              "      <td>57.7</td>\n",
              "      <td>72</td>\n",
              "      <td>-19.861111</td>\n",
              "      <td>1400000US13089023115</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83055</th>\n",
              "      <td>Tract 9402.02, Fremont</td>\n",
              "      <td>Fremont County</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>West</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>30.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-25.1</td>\n",
              "      <td>55.9</td>\n",
              "      <td>69</td>\n",
              "      <td>-18.985507</td>\n",
              "      <td>1400000US56013940202</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83056</th>\n",
              "      <td>Tract 9403.01, Fremont</td>\n",
              "      <td>Fremont County</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>West</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>37.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-18.3</td>\n",
              "      <td>55.9</td>\n",
              "      <td>69</td>\n",
              "      <td>-18.985507</td>\n",
              "      <td>1400000US56013940301</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83057</th>\n",
              "      <td>Tract 9403.02, Fremont</td>\n",
              "      <td>Fremont County</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>West</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>48.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>55.9</td>\n",
              "      <td>69</td>\n",
              "      <td>-18.985507</td>\n",
              "      <td>1400000US56013940302</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83058</th>\n",
              "      <td>Tract 9404, Fremont</td>\n",
              "      <td>Fremont County</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>West</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>59.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.9</td>\n",
              "      <td>55.9</td>\n",
              "      <td>69</td>\n",
              "      <td>-18.985507</td>\n",
              "      <td>1400000US56013940400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83059</th>\n",
              "      <td>Tract 9405, Fremont</td>\n",
              "      <td>Fremont County</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>West</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>48.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-7.4</td>\n",
              "      <td>55.9</td>\n",
              "      <td>69</td>\n",
              "      <td>-18.985507</td>\n",
              "      <td>1400000US56013940500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84093 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Geo_Name  ... 10_20_tract_difference\n",
              "12328  Tract 1103.01, Santa Cruz  ...                    inf\n",
              "53804     Tract 1596.02, Suffolk  ...                    inf\n",
              "53322     Tract 605.05, Saratoga  ...                    inf\n",
              "53425      Tract 7403, Schoharie  ...                    inf\n",
              "21943       Tract 231.15, DeKalb  ...                    inf\n",
              "...                          ...  ...                    ...\n",
              "83055     Tract 9402.02, Fremont  ...                    NaN\n",
              "83056     Tract 9403.01, Fremont  ...                    NaN\n",
              "83057     Tract 9403.02, Fremont  ...                    NaN\n",
              "83058        Tract 9404, Fremont  ...                    NaN\n",
              "83059        Tract 9405, Fremont  ...                    NaN\n",
              "\n",
              "[84093 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftKA9hxg4oaM",
        "colab_type": "text"
      },
      "source": [
        "### Demographic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zeTAJAu4oaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caab83bd-e3b8-4440-cbc5-0f7b8fd62153"
      },
      "source": [
        "#load both sets of demographic data, join\n",
        "temp1 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/nhgis0003_csv/nhgis0003_ds239_20185_2018_tract.csv', \n",
        "                    encoding='latin-1')\n",
        "temp2 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/data/nhgis0003_csv/nhgis0003_ds240_20185_2018_tract.csv', \n",
        "                    encoding='latin-1')\n",
        "demo = pd.merge(temp1, temp2, on=['GISJOIN', 'YEAR', 'REGIONA', 'DIVISIONA',\n",
        " 'STATE', 'STATEA', 'COUNTY', 'COUNTYA', 'COUSUBA', 'PLACEA', 'TRACTA',\n",
        "  'CONCITA', 'AIANHHA', 'RES_ONLYA', 'TRUSTA', 'AITSCEA', 'ANRCA', 'CBSAA',\n",
        " 'CSAA', 'METDIVA', 'NECTAA', 'CNECTAA', 'NECTADIVA', 'UAA', 'CDCURRA',\n",
        " 'SLDUA', 'SLDLA', 'ZCTA5A', 'SUBMCDA', 'SDELMA', 'SDSECA', 'SDUNIA',\n",
        " 'PUMA5A', 'BTTRA', 'NAME_E'])\n",
        "\n",
        "#create a new edited column so we can join with the response rate dfs\n",
        "# many different lengths so selecting substr that's always the same\n",
        "demo['tractNum'] = demo['NAME_E'].apply(lambda x: ' '.join(x.split(' ')[1:4]))\n",
        "tracts['tractNum'] = tracts['Geo_Name'].apply(lambda x: ' '.join(x.split(' ')[0:3]))\n",
        "\n",
        "# merge to create new df with response rates and demos for all tracts\n",
        "temp = pd.merge(tracts, demo, on='tractNum')\n",
        "\n",
        "#create new column adding up pop with rent > 30% income (homelessness marker)\n",
        "#temp['rent_30_more'] = (temp['rent_30_34.9'] + temp['rent_35_39.9'] \n",
        "#+ temp['rent_40_49.9'] + temp['rent_50_over'])\n",
        "\n",
        "#create column with % population black, hispanic, non-white\n",
        "#temp['non_white_pct'] = (temp['total_population'] - temp['white_alone']) * 100 / temp['total_population']\n",
        "#temp['black_pct'] = (temp['black_alone'] * 100) / temp['total_population']\n",
        "\n",
        "# check to see if column created\n",
        "#pd.set_option('display.max_columns', None)\n",
        "#list(temp.columns)\n",
        "temp"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Geo_Name</th>\n",
              "      <th>county</th>\n",
              "      <th>State</th>\n",
              "      <th>Region</th>\n",
              "      <th>Geo_Type</th>\n",
              "      <th>2020_tract_rate</th>\n",
              "      <th>2010_tract_rate</th>\n",
              "      <th>2020_tract_st_diff</th>\n",
              "      <th>2020_state_rate</th>\n",
              "      <th>2010_state_rate</th>\n",
              "      <th>10_20_state_difference</th>\n",
              "      <th>GEO_ID</th>\n",
              "      <th>10_20_tract_difference</th>\n",
              "      <th>tractNum</th>\n",
              "      <th>GISJOIN</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>REGIONA</th>\n",
              "      <th>DIVISIONA</th>\n",
              "      <th>STATE</th>\n",
              "      <th>STATEA</th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>COUNTYA</th>\n",
              "      <th>COUSUBA</th>\n",
              "      <th>PLACEA</th>\n",
              "      <th>TRACTA</th>\n",
              "      <th>BLKGRPA</th>\n",
              "      <th>CONCITA</th>\n",
              "      <th>AIANHHA</th>\n",
              "      <th>RES_ONLYA</th>\n",
              "      <th>TRUSTA</th>\n",
              "      <th>AITSCEA</th>\n",
              "      <th>ANRCA</th>\n",
              "      <th>CBSAA</th>\n",
              "      <th>CSAA</th>\n",
              "      <th>METDIVA</th>\n",
              "      <th>NECTAA</th>\n",
              "      <th>CNECTAA</th>\n",
              "      <th>NECTADIVA</th>\n",
              "      <th>UAA</th>\n",
              "      <th>CDCURRA</th>\n",
              "      <th>...</th>\n",
              "      <th>AJ3KM003</th>\n",
              "      <th>AJ3KM004</th>\n",
              "      <th>AJ3KM005</th>\n",
              "      <th>AJ3KM006</th>\n",
              "      <th>AJ3KM007</th>\n",
              "      <th>AJ3KM008</th>\n",
              "      <th>AJ3KM009</th>\n",
              "      <th>AJ3KM010</th>\n",
              "      <th>AJ3KM011</th>\n",
              "      <th>AJ38M001</th>\n",
              "      <th>AJ38M002</th>\n",
              "      <th>AJ38M003</th>\n",
              "      <th>AJ38M004</th>\n",
              "      <th>AJ38M005</th>\n",
              "      <th>AJ38M006</th>\n",
              "      <th>AJ68E001</th>\n",
              "      <th>AJ68E002</th>\n",
              "      <th>AJ68E003</th>\n",
              "      <th>AJ68E004</th>\n",
              "      <th>AJ68E005</th>\n",
              "      <th>AJ68E006</th>\n",
              "      <th>AJ69E001</th>\n",
              "      <th>AJ69E002</th>\n",
              "      <th>AJ69E003</th>\n",
              "      <th>AJ69E004</th>\n",
              "      <th>AJ69E005</th>\n",
              "      <th>AJ69E006</th>\n",
              "      <th>NAME_M_y</th>\n",
              "      <th>AJ68M001</th>\n",
              "      <th>AJ68M002</th>\n",
              "      <th>AJ68M003</th>\n",
              "      <th>AJ68M004</th>\n",
              "      <th>AJ68M005</th>\n",
              "      <th>AJ68M006</th>\n",
              "      <th>AJ69M001</th>\n",
              "      <th>AJ69M002</th>\n",
              "      <th>AJ69M003</th>\n",
              "      <th>AJ69M004</th>\n",
              "      <th>AJ69M005</th>\n",
              "      <th>AJ69M006</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tract 201, Autauga</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>64.9</td>\n",
              "      <td>70.6</td>\n",
              "      <td>5.4</td>\n",
              "      <td>59.5</td>\n",
              "      <td>72</td>\n",
              "      <td>-17.361111</td>\n",
              "      <td>1400000US01001020100</td>\n",
              "      <td>-0.080737</td>\n",
              "      <td>Tract 201, Autauga</td>\n",
              "      <td>G0100010020100</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>1</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>73</td>\n",
              "      <td>79</td>\n",
              "      <td>12</td>\n",
              "      <td>89</td>\n",
              "      <td>43</td>\n",
              "      <td>50</td>\n",
              "      <td>1923.0</td>\n",
              "      <td>1870.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Census Tract 201, Autauga County, Alabama</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tract 202, Autauga</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>65.6</td>\n",
              "      <td>70.1</td>\n",
              "      <td>6.1</td>\n",
              "      <td>59.5</td>\n",
              "      <td>72</td>\n",
              "      <td>-17.361111</td>\n",
              "      <td>1400000US01001020200</td>\n",
              "      <td>-0.064194</td>\n",
              "      <td>Tract 202, Autauga</td>\n",
              "      <td>G0100010020200</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>1</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>87</td>\n",
              "      <td>83</td>\n",
              "      <td>12</td>\n",
              "      <td>73</td>\n",
              "      <td>39</td>\n",
              "      <td>75</td>\n",
              "      <td>2028.0</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Census Tract 202, Autauga County, Alabama</td>\n",
              "      <td>192.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tract 203, Autauga</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.6</td>\n",
              "      <td>14.5</td>\n",
              "      <td>59.5</td>\n",
              "      <td>72</td>\n",
              "      <td>-17.361111</td>\n",
              "      <td>1400000US01001020300</td>\n",
              "      <td>0.005435</td>\n",
              "      <td>Tract 203, Autauga</td>\n",
              "      <td>G0100010020300</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>1</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>110</td>\n",
              "      <td>125</td>\n",
              "      <td>12</td>\n",
              "      <td>123</td>\n",
              "      <td>84</td>\n",
              "      <td>70</td>\n",
              "      <td>3476.0</td>\n",
              "      <td>3231.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Census Tract 203, Autauga County, Alabama</td>\n",
              "      <td>433.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tract 204, Autauga</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>78.1</td>\n",
              "      <td>78.4</td>\n",
              "      <td>18.6</td>\n",
              "      <td>59.5</td>\n",
              "      <td>72</td>\n",
              "      <td>-17.361111</td>\n",
              "      <td>1400000US01001020400</td>\n",
              "      <td>-0.003827</td>\n",
              "      <td>Tract 204, Autauga</td>\n",
              "      <td>G0100010020400</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>1</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>30.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>144</td>\n",
              "      <td>151</td>\n",
              "      <td>11</td>\n",
              "      <td>148</td>\n",
              "      <td>78</td>\n",
              "      <td>66</td>\n",
              "      <td>3831.0</td>\n",
              "      <td>3720.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Census Tract 204, Autauga County, Alabama</td>\n",
              "      <td>337.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tract 206, Autauga</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>South</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>66.7</td>\n",
              "      <td>71.9</td>\n",
              "      <td>7.2</td>\n",
              "      <td>59.5</td>\n",
              "      <td>72</td>\n",
              "      <td>-17.361111</td>\n",
              "      <td>1400000US01001020600</td>\n",
              "      <td>-0.072323</td>\n",
              "      <td>Tract 206, Autauga</td>\n",
              "      <td>G0100010020600</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>1</td>\n",
              "      <td>Autauga County</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>87.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>122</td>\n",
              "      <td>121</td>\n",
              "      <td>12</td>\n",
              "      <td>125</td>\n",
              "      <td>73</td>\n",
              "      <td>84</td>\n",
              "      <td>3705.0</td>\n",
              "      <td>3647.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Census Tract 206, Autauga County, Alabama</td>\n",
              "      <td>342.0</td>\n",
              "      <td>336.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65852</th>\n",
              "      <td>Tract 7505.01, Yauco</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>33.2</td>\n",
              "      <td>70.4</td>\n",
              "      <td>10.6</td>\n",
              "      <td>22.6</td>\n",
              "      <td>54</td>\n",
              "      <td>-58.148148</td>\n",
              "      <td>1400000US72153750501</td>\n",
              "      <td>-0.528409</td>\n",
              "      <td>Tract 7505.01, Yauco</td>\n",
              "      <td>G7201530750501</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>72</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>750501</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>162</td>\n",
              "      <td>161</td>\n",
              "      <td>30</td>\n",
              "      <td>152</td>\n",
              "      <td>59</td>\n",
              "      <td>124</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6303.0</td>\n",
              "      <td>6148.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Census Tract 7505.01, Yauco Municipio, Puerto ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>872.0</td>\n",
              "      <td>868.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65853</th>\n",
              "      <td>Tract 7505.02, Yauco</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>39.2</td>\n",
              "      <td>73.4</td>\n",
              "      <td>16.6</td>\n",
              "      <td>22.6</td>\n",
              "      <td>54</td>\n",
              "      <td>-58.148148</td>\n",
              "      <td>1400000US72153750502</td>\n",
              "      <td>-0.465940</td>\n",
              "      <td>Tract 7505.02, Yauco</td>\n",
              "      <td>G7201530750502</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>72</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>750502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>85</td>\n",
              "      <td>78</td>\n",
              "      <td>17</td>\n",
              "      <td>77</td>\n",
              "      <td>18</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2316.0</td>\n",
              "      <td>2201.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Census Tract 7505.02, Yauco Municipio, Puerto ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>386.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65854</th>\n",
              "      <td>Tract 7505.03, Yauco</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>25.9</td>\n",
              "      <td>63.4</td>\n",
              "      <td>3.3</td>\n",
              "      <td>22.6</td>\n",
              "      <td>54</td>\n",
              "      <td>-58.148148</td>\n",
              "      <td>1400000US72153750503</td>\n",
              "      <td>-0.591483</td>\n",
              "      <td>Tract 7505.03, Yauco</td>\n",
              "      <td>G7201530750503</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>72</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>750503</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>82</td>\n",
              "      <td>70</td>\n",
              "      <td>29</td>\n",
              "      <td>66</td>\n",
              "      <td>24</td>\n",
              "      <td>65</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2244.0</td>\n",
              "      <td>2164.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Census Tract 7505.03, Yauco Municipio, Puerto ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>451.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65855</th>\n",
              "      <td>Tract 7506.01, Yauco</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>27.0</td>\n",
              "      <td>67.1</td>\n",
              "      <td>4.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>54</td>\n",
              "      <td>-58.148148</td>\n",
              "      <td>1400000US72153750601</td>\n",
              "      <td>-0.597615</td>\n",
              "      <td>Tract 7506.01, Yauco</td>\n",
              "      <td>G7201530750601</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>72</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>750601</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>166</td>\n",
              "      <td>148</td>\n",
              "      <td>44</td>\n",
              "      <td>126</td>\n",
              "      <td>74</td>\n",
              "      <td>118</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4107.0</td>\n",
              "      <td>4007.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Census Tract 7506.01, Yauco Municipio, Puerto ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>668.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65856</th>\n",
              "      <td>Tract 7506.02, Yauco</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>Census Tract</td>\n",
              "      <td>18.2</td>\n",
              "      <td>57.8</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>54</td>\n",
              "      <td>-58.148148</td>\n",
              "      <td>1400000US72153750602</td>\n",
              "      <td>-0.685121</td>\n",
              "      <td>Tract 7506.02, Yauco</td>\n",
              "      <td>G7201530750602</td>\n",
              "      <td>2014-2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>72</td>\n",
              "      <td>Yauco Municipio</td>\n",
              "      <td>153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>750602</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>140</td>\n",
              "      <td>112</td>\n",
              "      <td>42</td>\n",
              "      <td>86</td>\n",
              "      <td>70</td>\n",
              "      <td>96</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2511.0</td>\n",
              "      <td>2492.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Census Tract 7506.02, Yauco Municipio, Puerto ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>591.0</td>\n",
              "      <td>589.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65857 rows × 301 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Geo_Name            county  ... AJ69M005 AJ69M006\n",
              "0        Tract 201, Autauga    Autauga County  ...      NaN      NaN\n",
              "1        Tract 202, Autauga    Autauga County  ...      NaN      NaN\n",
              "2        Tract 203, Autauga    Autauga County  ...      NaN      NaN\n",
              "3        Tract 204, Autauga    Autauga County  ...      NaN      NaN\n",
              "4        Tract 206, Autauga    Autauga County  ...      NaN      NaN\n",
              "...                     ...               ...  ...      ...      ...\n",
              "65852  Tract 7505.01, Yauco   Yauco Municipio  ...     19.0     22.0\n",
              "65853  Tract 7505.02, Yauco   Yauco Municipio  ...     20.0      7.0\n",
              "65854  Tract 7505.03, Yauco   Yauco Municipio  ...      8.0      7.0\n",
              "65855  Tract 7506.01, Yauco   Yauco Municipio  ...     14.0     14.0\n",
              "65856  Tract 7506.02, Yauco   Yauco Municipio  ...     15.0     14.0\n",
              "\n",
              "[65857 rows x 301 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZbSK38DkSq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2f34df88-62f2-4222-9bb9-edd7b9113e2c"
      },
      "source": [
        "print(\n",
        "    \"There are\", len(tracts), \"observations in the tracts df but only \\n\",\n",
        "    len(temp), \"after joining with the demographic data, \\n\",\n",
        "    \"a difference of\", len(tracts) - len(temp)\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 84093 observations in the tracts df but only \n",
            " 65857 after joining with the demographic data, \n",
            " a difference of 18236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QapgMX_MmHHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60ab2f50-20d4-45f3-a765-a1c04dab54f7"
      },
      "source": [
        "## difference in row numbers\n",
        "# Identify what values are in tracts and not in demo\n",
        "key_diff11 = set(tracts.tractNum).difference(demo.tractNum)\n",
        "key_diff1 = pd.DataFrame(sorted(list(key_diff11)))\n",
        "key_diff1 = key_diff1.rename(columns={0:'tractNum'})\n",
        "\n",
        "# Identify what values are in demo and not in tracts\n",
        "key_diff22 = set(demo.tractNum).difference(tracts.tractNum)\n",
        "key_diff2 = pd.DataFrame(list(key_diff22))\n",
        "key_diff2 = key_diff2.rename(columns={0:'tractNum'})\n",
        "\n",
        "#key_diff1.to_csv(\"/gdrive/My Drive/0USA Today/unpaired_tracts.csv\")\n",
        "#key_diff2.to_csv(\"/gdrive/My Drive/0USA Today/unpaired_demos.csv\")\n",
        "#temp['tractNum'].to_csv(\"/gdrive/My Drive/0USA Today/paired.csv\")\n",
        "\n",
        "#print(key_diff1, \"\\n\\n\",\n",
        " #     key_diff2)\n",
        "print(\"There are\", len(key_diff1), \n",
        "      \"tracts in the tracts df that are not in the demographics df \\n\",\n",
        "      \"And there are\", len(key_diff2), \n",
        "      \"tracts in the demo df not in the tracts df \\n\",\n",
        "      \"That's\", len(key_diff1) + len(key_diff2), \"unpaired values, which is \\n\",\n",
        "      (len(key_diff1) + len(key_diff2)) * 100 / len(tracts), \"% of observations in the tracts df \\n\\n\")\n",
        "\n",
        "print(\n",
        "    '# Tracts per State not paired from demo df:\\n',\n",
        "    pd.merge(key_diff2, demo[['STATE', 'tractNum']], on='tractNum').STATE.value_counts(), \"\\n\\n\",\n",
        "    '# Tracts per State not paired from tracts df: \\n',\n",
        "    pd.merge(key_diff1, tracts[['State', 'tractNum']], on='tractNum').State.value_counts()\n",
        ")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 21914 tracts in the tracts df that are not in the demographics df \n",
            " And there are 11616 tracts in the demo df not in the tracts df \n",
            " That's 33530 unpaired values, which is \n",
            " 39.87252208863996 % of observations in the tracts df \n",
            "\n",
            "\n",
            "# Tracts per State not paired from demo df:\n",
            " Texas                   1459\n",
            "California              1135\n",
            "Florida                  951\n",
            "Georgia                  703\n",
            "New York                 573\n",
            "North Carolina           453\n",
            "Michigan                 362\n",
            "Ohio                     337\n",
            "Pennsylvania             293\n",
            "Washington               287\n",
            "Virginia                 284\n",
            "Missouri                 250\n",
            "Louisiana                238\n",
            "Arizona                  230\n",
            "Tennessee                221\n",
            "South Carolina           216\n",
            "Alabama                  216\n",
            "Indiana                  195\n",
            "Colorado                 189\n",
            "New Jersey               185\n",
            "Mississippi              182\n",
            "Oklahoma                 179\n",
            "Kentucky                 171\n",
            "Massachusetts            163\n",
            "Minnesota                160\n",
            "Hawaii                   158\n",
            "Oregon                   157\n",
            "Illinois                 153\n",
            "Wisconsin                142\n",
            "Maryland                 137\n",
            "Arkansas                 127\n",
            "Puerto Rico              112\n",
            "Utah                     105\n",
            "Kansas                   103\n",
            "Idaho                    101\n",
            "Nevada                    90\n",
            "New Mexico                90\n",
            "Connecticut               63\n",
            "West Virginia             59\n",
            "New Hampshire             57\n",
            "Iowa                      55\n",
            "Maine                     48\n",
            "Montana                   48\n",
            "Delaware                  43\n",
            "Alaska                    35\n",
            "Wyoming                   28\n",
            "District of Columbia      27\n",
            "North Dakota              27\n",
            "South Dakota              25\n",
            "Rhode Island              25\n",
            "Vermont                   19\n",
            "Nebraska                  19\n",
            "Name: STATE, dtype: int64 \n",
            "\n",
            " # Tracts per State not paired from tracts df: \n",
            "  Texas                   2974\n",
            " California              2126\n",
            " Florida                 1763\n",
            " Georgia                 1539\n",
            " New York                 921\n",
            " North Carolina           916\n",
            " Washington               594\n",
            " Ohio                     542\n",
            " Virginia                 530\n",
            " Missouri                 509\n",
            " Pennsylvania             481\n",
            " Alabama                  475\n",
            " Louisiana                471\n",
            " Michigan                 445\n",
            " Arizona                  438\n",
            " South Carolina           413\n",
            " Tennessee                404\n",
            " Mississippi              402\n",
            " Colorado                 380\n",
            " Kentucky                 375\n",
            " Indiana                  365\n",
            " New Jersey               339\n",
            " Oklahoma                 330\n",
            " Minnesota                325\n",
            " Oregon                   318\n",
            " Illinois                 287\n",
            " Massachusetts            268\n",
            " Arkansas                 268\n",
            " Idaho                    261\n",
            " Wisconsin                257\n",
            " Hawaii                   229\n",
            " Utah                     219\n",
            " Maryland                 187\n",
            " New Mexico               175\n",
            " Nevada                   170\n",
            " Kansas                   153\n",
            " Iowa                     127\n",
            " West Virginia            121\n",
            " New Hampshire            114\n",
            " Connecticut               98\n",
            " Montana                   96\n",
            " Puerto Rico               90\n",
            " Maine                     87\n",
            " Delaware                  81\n",
            " Wyoming                   55\n",
            " North Dakota              51\n",
            " District of Columbia      50\n",
            " South Dakota              45\n",
            " Nebraska                  38\n",
            " Rhode Island              38\n",
            " Vermont                   30\n",
            " Alaska                    27\n",
            "Name: State, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMopCxxOMxxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "73427853-31ac-4787-d09a-dd00500f68a7"
      },
      "source": [
        "demo[key_diff2].STATE.value_counts()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-cd5e0948c1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_diff2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2785\u001b[0m         \u001b[0;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   8917\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8918\u001b[0m         return self._where(\n\u001b[0;32m-> 8919\u001b[0;31m             \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8920\u001b[0m         )\n\u001b[1;32m   8921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   8664\u001b[0m         \u001b[0;31m# make sure we are boolean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8665\u001b[0m         \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8666\u001b[0;31m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8668\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Boolean array expected for the condition, not {dtype}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   4151\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m             \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         )\n\u001b[1;32m   4155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6235\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6236\u001b[0m                 new_data = self._data.fillna(\n\u001b[0;32m-> 6237\u001b[0;31m                     \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6238\u001b[0m                 )\n\u001b[1;32m   6239\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fillna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_and_operate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit_and_operate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msplit_and_operate\u001b[0;34m(self, mask, f, inplace)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;31m# need a new block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(mask, val, idx)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# operate column-by-column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce_to_target_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# slice out our block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcoerce_to_target_dtype\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;31m# we don't upcast to bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         elif (self.is_float or self.is_complex) and (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EoaTaJXA4oaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.std()Returns the standard deviation of each column\n",
        "#df.corr()Returns the correlation between columns in a data frame\n",
        "\n",
        "#In order to get # of null/missing values for each column, run \n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.isnull(temp).sum()\n",
        "\n",
        "# make a dataframe of all rows with na value\n",
        "temp1 = temp[temp.isna().any(axis=1)]\n",
        "temp1\n",
        "# how many nas in each state\n",
        "temp2 = temp1['State'].value_counts()\n",
        "temp2 = pd.DataFrame(temp2)\n",
        "temp2 = temp2.reset_index().rename(columns={'index':'state', 'State':'count_na'})\n",
        "temp2\n",
        "#compare to total \n",
        "temp3 = temp['State'].value_counts()\n",
        "temp3 = pd.DataFrame(temp3)\n",
        "temp3 = temp3.reset_index().rename(columns={'index':'state', 'State':'count'})\n",
        "temp3\n",
        "\n",
        "#see what percent of state values of na\n",
        "#Puerto Rico will lose the greatest % if these are dropped\n",
        "temp4 = pd.merge(temp2, temp3, on=['state'])\n",
        "temp4['na_percent'] = (temp4['count_na']*100) / temp4['count']\n",
        "temp4\n",
        "\n",
        "#how many total nas? --> 1171\n",
        "sum(temp4['count_na'])\n",
        "\n",
        "#nas account for what total % of all rows --> 1.82\n",
        "(sum(temp4['count_na'])*100) / sum(temp4['count'])\n",
        "\n",
        "#Less than 2% of total, so for now will drop those rows\n",
        "# before df had 64413 rows\n",
        "#df = temp.dropna()    #now has 63242 rows, 1171 difference (total # nas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_8zDZ3ghLTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if any nas\n",
        "#pd.set_option('display.max_rows', None)\n",
        "#print(pd.isnull(df).sum())\n",
        "\n",
        "#still 52 states? (50 + DC and PR)\n",
        "#print(\"Number states: \", len(df['State'].unique()))\n",
        "\n",
        "#compare tract numbers now to before na drop\n",
        "temp1 = pd.DataFrame(temp.groupby('State')['Geo_Name'].nunique()).rename(columns={'Geo_Name':'beforeDrop'})\n",
        "temp2 = pd.DataFrame(df.groupby('State')['Geo_Name'].nunique()).rename(columns={'Geo_Name':'afterDrop'})\n",
        "temp3 = pd.merge(temp1, temp2, left_index = True, right_index=True)\n",
        "#number tracts dropped from each state\n",
        "temp3['numDrop'] = temp3['beforeDrop'] - temp3['afterDrop']\n",
        "# the percentage of total tracts dropped\n",
        "temp3['dropPct'] = temp3['numDrop']*100 / temp3['beforeDrop']\n",
        "#temp3 #puerto rico loses the most tracts at 5.7%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo_-Pu9E4oaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#return column size\n",
        "pd.set_option('display.max_columns', 15)\n",
        "#pd.set_option('display.max_row', 50)\n",
        "\n",
        "#only select columns we want\n",
        "cols = ['Geo_Name', 'county', 'State','Region',\n",
        "'2020_tract_rate', '2010_tract_rate', '2020_tract_st_diff',\n",
        "'2020_state_rate', '2010_state_rate',\n",
        "'10_20_state_difference', '10_20_tract_difference',\n",
        "'total_population', 'white_alone', 'black_alone', 'black_pct',\n",
        "'amerindian_alone', 'non_white_pct',\n",
        "'total_education', 'no_school', 'some_school', 'diploma', \n",
        "'ged', 'some_college','associate','bachelor',\n",
        "'master','prof_school','doctorate',\n",
        "'income_poverty_ratio','language_total',\n",
        "'lang_english_only','lang_spanish','lang_spanish_limited_english',\n",
        "'median_household_income','per_capita_income',\n",
        "'total_houses','occupied_houses','vacant_houses',\n",
        "'total_occupied_houses','owner_occupied','renter_occupied',\n",
        "'median_gross_rent','rent_to_income','rent_30_more',\n",
        "'total_computer_status','has_computer','dial_up_computer',\n",
        "'broadband_computer','no_internet_computer','no_computer',\n",
        "'employment_total','labor_force','civilian_labor_force',\n",
        "'civilian_employed','civilian_unemployed',\n",
        "'us_pop','us_born','us_territory_born','us_born_abroad',\n",
        "'us_naturalization','not_us_citizen',\n",
        "'total_pr','pr_born','pr_us_born','pr_born_abroad',\n",
        "'pr_naturalization','pr_not_us_citizen']\n",
        "\n",
        "df = df[cols]\n",
        "#print df with no nas\n",
        "df.to_csv(\"/gdrive/My Drive/0USA Today/all_rates_demos_merged.csv\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdZ0zN4nA1ek",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAjKrWdeyR9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##see all dfs in memory\n",
        "%whos DataFrame\n",
        "\n",
        "#### Existing DFs:\n",
        "\n",
        "#dataframe with all years, states, tracts, demographics\n",
        "#df\n",
        "\n",
        "#2010 and 2020 states\n",
        "#states\n",
        "\n",
        "#2010 States\n",
        "#states2010\n",
        "\n",
        "#2020 States\n",
        "#states2020\n",
        "\n",
        "#2010 and 2020 tracts and states\n",
        "#tracts\n",
        "\n",
        "#2020 tracts paired with states, includes int data\n",
        "#tracts2020states\n",
        "\n",
        "# ignore all dfs with \"temp\" in name "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUrmR-IrfcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get average state rate and see how many are above average\n",
        "i = states.mean(axis=0)['2020_state_rate']\n",
        "print(\n",
        "    \"61.8% is the current nationwide response rate and\",\n",
        "    np.sum(states2020['2020_state_rate'] > 61.8),\n",
        "    \"states exceed that\", \"\\n\")\n",
        "print(states2020[states2020['2020_state_rate'] > 61.8].State.to_list(), \"/n\")\n",
        "\n",
        "temp = states2020['2020_state_rate'] > 61.8\n",
        "\n",
        "#how many in each region?\n",
        "states2020[temp].Region.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKSDVX0vZAew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#how many tracts are > than state avg?\n",
        "\n",
        "#tract2020States.count(tract2020States['2020_tract_st_diff'] > 0)\n",
        "print(np.sum(tract2020states['2020_tract_st_diff'] > 0), \"tracts out of\", \n",
        "      len(tract2020states), \n",
        "      \"total (\", \n",
        "      (np.sum(tract2020states['2020_tract_st_diff'] > 0) * 100) / len(tract2020states), \"% )\",\n",
        "      \"currently have greater census response rates than their state average\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw0UAsUeC_us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get info on 1000 tracks with greatest drop in response rate\n",
        "big_drop = tracts.sort_values(by='10_20_tract_difference', ascending=True).head(1000)\n",
        "big_drop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05uTu0dMD3k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lowest tract rates\n",
        "lowest = tracts.sort_values(by='2020_tract_rate', ascending=True).head(1000)\n",
        "lowest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuG9IMvlwcHv",
        "colab_type": "text"
      },
      "source": [
        "### National Comparative Rankings 2010 vs 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iwBMqvP9xxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Discrepancies? Shouldn't these all match up?\n",
        "# Average is sum / #obs\n",
        "print(\n",
        "  \"2010 State Resonse Average from states data:\",\n",
        "    states.mean(axis=0)['2010_state_rate'], \"\\n\",\n",
        "  \"2010 States Response Average from df data:\",\n",
        "    df.mean(axis=0)['2010_state_rate'], \"\\n\",\n",
        "  \"2010 Tract Response Average from df data:\",\n",
        "    df.mean(axis=0)['2010_tract_rate'],  \"\\n\"\n",
        ")\n",
        "## totals intended to be sum(percentages) / 100 (denominator)\n",
        "print(\n",
        "  \"2010 State Resonse Total from states data:\",\n",
        "    (states['2010_state_rate'].sum()) / 100, \"\\n\",\n",
        "  \"2010 States Response Total from df data:\",\n",
        "    (df['2010_state_rate'].sum()) / 100, \"\\n\",\n",
        "  \"2010 Tract Response Total from df data:\",\n",
        "    (df['2010_tract_rate'].sum()) / 100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qw6ix7B4oaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average difference between current state rates and 2010 state rates as of 6/15/20\n",
        "#takes a while to run so commented out\n",
        "#df.mean(axis=0)['10_20_state_difference']\n",
        "\n",
        "#average 2020 response rate across states?\n",
        "print(\n",
        "  \"2020 State Resonse Average from states data:\",\n",
        "    states.mean(axis=0)['2020_state_rate'], \"\\n\",\n",
        "  \"2020 States Response Average from df data:\",\n",
        "    df.mean(axis=0)['2020_state_rate'], \"\\n\",\n",
        "  \"2020 Tract Response Average from df data:\",\n",
        "    df.mean(axis=0)['2020_tract_rate'], \"\\n\"\n",
        ")\n",
        "\n",
        "#is the total not sum(numerator) / 100? where numerator is percentage response rate?\n",
        "print(\n",
        "  \"2020 State Resonse Total from states data:\",\n",
        "    (states['2020_state_rate'].sum()) / (100), \"\\n\",\n",
        "  \"2020 States Response Total from df data:\",\n",
        "    (df['2020_state_rate'].sum()) / (100), \"\\n\",\n",
        "  \"2020 Tract Response Total from df data:\",\n",
        "    (df['2020_tract_rate'].sum()) / (100)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBtQ-tkD4oaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference by region\n",
        "states.groupby('Region').mean().sort_values(by='10_20_state_difference', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db386fTQ4iiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assign ranks to states based on comparative response rate\n",
        "states['2020_rank'] = states['2020_state_rate'].rank(method='max', ascending=False)\n",
        "states['2010_rank'] = states['2010_state_rate'].rank(method='max', ascending=False)\n",
        "\n",
        "#pull ranks into separate dataframe\n",
        "state_ranks = states[['State', '2020_rank', '2010_rank']].sort_values(by='2020_rank')\n",
        "\n",
        "#show change in rank from 2010 to 2020\n",
        "#negative number means a state has a lower 2020 response rate and has gone down in rankings\n",
        "state_ranks['rank_change'] = state_ranks['2010_rank'] - state_ranks['2020_rank']\n",
        "#state_ranks.sort_values(by='rank_change', ascending=True)\n",
        "\n",
        "#see how many states only changed 2 or fewer positions\n",
        "#small_change = state_ranks[state_ranks.rank_change.between(-2, 2, inclusive=True)].sort_values(by='rank_change')\n",
        "#small_change\n",
        "#16 states have stayed ~similar in the rankings, and this seems to impact\n",
        "#states with both high and low response rates\n",
        "#small_change.mean(axis=0)['2020_rank']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjhY7qa-UCO",
        "colab_type": "text"
      },
      "source": [
        "### Internet Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbOu9mByHce0",
        "colab_type": "text"
      },
      "source": [
        "Internet usage is only available for 2020 rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7DBXHjYM-Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Percent of response rate not from internet\n",
        "\n",
        "states2020.sort_values(by='state_not_int_pct', ascending=False)\n",
        "print(\n",
        "    \"The average state response rate to the census NOT conducted online:\",\n",
        "    states2020.mean(axis=0)['state_not_int_pct'], \"/n\",\n",
        "    states2020.mean(axis=0)['state_not_int']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c4Kc5YV4oZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average non internet response rate\n",
        "states2020.groupby(by='State').mean().sort_values(by='state_internet', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1moWoRN4oZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# highest non-internet response rate (not_int)\n",
        "states2020.sort_values(by='state_not_int', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajtMfXEB4oZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['state_not_int']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5-66yFC4oZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['state_internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rS4qL6f4oZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['2020_state_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZPt0jX4oZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Without Puerto Rico\n",
        "\n",
        "#make non-pr df\n",
        "no_pr = states2020[states2020['State'] != 'Puerto Rico']\n",
        "\n",
        "# average internet response\n",
        "no_pr.mean(axis=0)['state_internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Qif8pR4oZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average overall response rate\n",
        "no_pr.mean(axis=0)['2020_state_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tN9xyjpHg9t",
        "colab_type": "text"
      },
      "source": [
        "### Region Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWUbAvs4oZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average by region\n",
        "# NOTE as tribal tracts are not assigned to a state they do not have a corresponding region and thus are not counted in the regional calculations\n",
        "states.groupby('Region').mean().sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AggzDxDA4oZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference as of 6/15/20\n",
        "#this can take a while to run so is commented out unless needed\n",
        "#tracts.mean(axis=0)['10_20_tract_difference']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZmwRdx4oaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference by region\n",
        "tracts.groupby('Region').mean().sort_values(by='10_20_tract_difference', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qug7mLZl-rCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tract average differences vs state rates\n",
        "tracts.groupby('State').mean().sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmLScMTr4oZQ",
        "colab_type": "text"
      },
      "source": [
        "### Tribal tracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSdZysHS4oZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create df with response rates in tribal tracts\n",
        "tribal = tracts2020[tracts2020['Geo_Type'].str.contains(\"Tribal\")]\n",
        "tribal.sort_values(by='2020_tract_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVcFRIn4oZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### tribal areas and tracts stats\n",
        "\n",
        "#mean non internet response\n",
        "tribal.mean(axis=0)['tract_not_int'] #8.37%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjVmQ5e_4oZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean internet response rate\n",
        "tribal.mean(axis=0)['internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euvyx-gL4oZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean overall response rate\n",
        "tribal.mean(axis=0)['2020_tract_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5b3R3834oZb",
        "colab_type": "text"
      },
      "source": [
        "### Tracts with 0 overall response rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eukXYcJx4oZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Tracts with 0 cumulative response rate\n",
        "is_zero = df['2020_tract_rate'] == 0\n",
        "zeros = df[is_zero]\n",
        "zeros.sort_values(by='State')\n",
        "\n",
        "print(\n",
        "    \"Number of tracts with 0 cumulative response rate:\", len(zeros), \"\\n\"\n",
        "    )\n",
        "\n",
        "#make dataframe of states with # tracts with 0%, number total tracts, and what % of total tracts are 0\n",
        "temp = pd.DataFrame(zeros['State'].value_counts())\n",
        "temp2 = pd.DataFrame(tracts['State'].value_counts())\n",
        "temp3 = pd.merge(temp, temp2, right_index=True, left_index=True)\n",
        "#rename the columns\n",
        "temp3 = temp3.rename(columns={\"State_x\": \"0_tracts\", \"State_y\" : \"total_tracts\"})\n",
        "#compute percentage\n",
        "temp3['0_percent'] = temp3['0_tracts'] * 100 / temp3['total_tracts']\n",
        "temp3\n",
        "\n",
        "zeros.sort_values(by='State')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L3k3y3FIHS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zeros.mean('black_pct')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPFHo4nO4oaU",
        "colab_type": "text"
      },
      "source": [
        "## Regressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn2rfAXWrfBe",
        "colab_type": "text"
      },
      "source": [
        "### With Puerto Rico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKBskyL7s-xu",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SHooFoBrrYEc",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = df[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = df[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "print(model20.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cbIp7LrSrYEg",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PToZ-lAorYEh"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R_dZfFsOrYEi",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "print(norm_model20.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fuv49LFwrYEk",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ECGhvxrhrYEl"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPMtG8ozrYEm",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = df[['total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = df[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "print(model10.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v_9tWG5drYEp",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "43-byZJzrYEq"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4bR0BjIrYEr",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "print(norm_model10.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ro4o8GDNrYEs",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXjoZqoZubCg",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "co5U07EArYEu",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = df[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other', 'income_poverty_ratio', 'per_capita_income',\n",
        " 'civilian_employed', 'civilian_unemployed',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income','rent_30_more',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer',\n",
        " 'us_born', 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = df[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "print(model_ed.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lm1iHnSurYEw",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Okny5FRDrYEx",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "print(norm_model_ed.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nccgx89crqt4",
        "colab_type": "text"
      },
      "source": [
        "### Without Puerto Rico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbsOPCbT4oaU",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd46DCij4oaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "#df without puerto rico for regression \n",
        "no_pr = df[df['Region'] != 'Puerto Rico']\n",
        "#this is different from earlier code no_pr = states[states.State != 'Puerto Rico']\n",
        "#earlier code omitted Puerto Rico from state level data. this eliminates from tract level data\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = no_pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = no_pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZthvp0R4oaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0npA7T4oaZ",
        "colab_type": "text"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85hPJc_O4oaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "norm_model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQfOymD4oab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29JVbcP4oad",
        "colab_type": "text"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xixKDYjY4oad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = no_pr[['total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = no_pr[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfY5LKEc4oag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3fc89-J4oaj",
        "colab_type": "text"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlwfXss24oaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "norm_model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM2yaM3d4oal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhxSdjQsFBs",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKbhPPF44oao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = no_pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other', 'income_poverty_ratio', 'per_capita_income',\n",
        " 'civilian_employed', 'civilian_unemployed',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income','rent_30_more',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer',\n",
        " 'us_born', 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = no_pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_WySxM4oaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceNe_aTSasfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "norm_model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfVDv7agtnz_",
        "colab_type": "text"
      },
      "source": [
        "### Puerto Rico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1AaDVLtr9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create df with just puerto rico\n",
        "is_pr = df['Region'] == 'Puerto Rico'\n",
        "pr = df[is_pr]\n",
        "pr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tYdF-C1cu1y8"
      },
      "source": [
        "#### 2020 regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RlidAAwwu1y-",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cvkw34rku1zA",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JVacRXRu1zB"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5KAHuRvHu1zC",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "norm_model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2jTl88Abu1zE",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eBcoXR_Iu1zG"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRFQpznKu1zG",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = pr[['total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = pr[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6CS4y7X_u1zI",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-pAJMVeu1zK"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BtAXZ8Zeu1zK",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "norm_model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wxTWDr54u1zM",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KsqdFNHru1zN"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnSLhYOwu1zN",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other', 'income_poverty_ratio', 'per_capita_income',\n",
        " 'civilian_employed', 'civilian_unemployed',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income','rent_30_more',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer',\n",
        " 'us_born', 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAFrD4JRu1zQ",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QGqYmMH6u1zS",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "norm_model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}