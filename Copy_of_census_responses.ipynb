{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of census-responses.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0TAdi8gb4oZK",
        "WAjhY7qa-UCO",
        "2tN9xyjpHg9t",
        "kmLScMTr4oZQ",
        "S5b3R3834oZb",
        "Tn2rfAXWrfBe",
        "aKBskyL7s-xu",
        "PToZ-lAorYEh",
        "ECGhvxrhrYEl",
        "43-byZJzrYEq",
        "mXjoZqoZubCg",
        "Nccgx89crqt4",
        "tbsOPCbT4oaU",
        "mL0npA7T4oaZ",
        "c29JVbcP4oad",
        "h3fc89-J4oaj",
        "twhxSdjQsFBs",
        "CfVDv7agtnz_",
        "tYdF-C1cu1y8",
        "7JVacRXRu1zB",
        "eBcoXR_Iu1zG",
        "c-pAJMVeu1zK",
        "KsqdFNHru1zN"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdiffendal/USAT/blob/master/Copy_of_census_responses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbXbhig24oZG",
        "colab_type": "text"
      },
      "source": [
        "# 2020 Census Response Rate Analysis\n",
        "\n",
        "### Theresa Diffendal, USA Today data intern, 06/2020\n",
        "\n",
        "#### 2020 response rates from: https://2020census.gov/en/response-rates.html\n",
        "#### 2010 response rates from: https://api.census.gov/data/2010/dec/responserate/variables.html\n",
        "#### Demographic information in 2014-2018 ACS 5-year-estimate from: https://data2.nhgis.org/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TAdi8gb4oZK",
        "colab_type": "text"
      },
      "source": [
        "## Column Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dWSiayi_y6Z",
        "colab_type": "text"
      },
      "source": [
        "GEO_ID = Geographic Identifier\n",
        "\n",
        "RESP_DATE = Posting Date\n",
        "\n",
        "State = name of state (one of the 50 states, District of Columbia, Puerto Rico, or NaN)\n",
        "\n",
        "Geo_Name = name of the tract, county, state\n",
        "\n",
        "Region = region of the U.S. in which state is located as defined by census map at https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
        "\n",
        "Geo_Type = type of geography; possible answers include Census Tract, Congressional District, Consolidated City, Country, County, County Subdivision, Place, Region, State, Tribal Tract, Tribal Area\n",
        "\n",
        "DRRINT = Daily Self-Response Rate - Internet\n",
        "\n",
        "DRRALL = Daily Self-Response Rate – Overall\n",
        "\n",
        "CRRINT = Cumulative Self-Response Rate - Internet; renamed internet\n",
        "\n",
        "not_int = new calculated column showing response rate NOT from internet\n",
        "\n",
        "CRRALL = Cumulative Self-Response Rate – Overall; renamed 2020_rate\n",
        "\n",
        "DINTMIN = Minimum Daily Internet Self-Response Rate\n",
        "\n",
        "DMIN = Minimum Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMIN = Minimum Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMIN = Minimum Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTMAX = Maximum Daily Internet Self-Response Rate\n",
        "\n",
        "DMAX = Maximum Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMAX = Maximum Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMAX = Maximum Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTAVG = Average Daily Internet Self-Response Rate\n",
        "\n",
        "DAVG = Average Daily Overall Self-Response Rate\n",
        "\n",
        "CINTAVG = Average Cumulative Internet Self-Response Rate\n",
        "\n",
        "CAVG = Average Cumulative Overall Self-Response Rate\n",
        "\n",
        "DINTMED = Median Daily Internet Self-Response Rate\n",
        "\n",
        "DMED = Median Daily Overall Self-Response Rate\n",
        "\n",
        "CINTMED = Median Cumulative Internet Self-Response Rate\n",
        "\n",
        "CMED = Median Cumulative Overall Self-Response Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxd7lfhbqD3W",
        "colab_type": "text"
      },
      "source": [
        "## Read, Merge, Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDwZx7aHAWpf",
        "colab_type": "text"
      },
      "source": [
        "### Initial Load and Merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip_J3r424oZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in 2020 response rates\n",
        "initial_df = pd.read_csv('https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/decennialrr2020.csv')\n",
        "# had to download from https://www2.census.gov/programs-surveys/decennial/2020/data/2020map/2020/ resave as UTF-8 CSV, hence the 2\n",
        "crosswalk = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/decennialrr2020_crosswalkfile2.csv')\n",
        "# states paired with region as defined by census map at https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
        "regions = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/state_region.csv')\n",
        "\n",
        "# merge responses and crosswalk\n",
        "temp = pd.merge(initial_df, crosswalk, on='GEO_ID')\n",
        "\n",
        "#merge merged1 with region data\n",
        "merged = pd.merge(temp, regions, on='State')\n",
        "\n",
        "# create column showing responses not from internet\n",
        "merged['not_int'] = merged.CRRALL - merged.CRRINT\n",
        "merged['not_int_pct'] = (merged.not_int) * 100 / merged.CRRALL\n",
        "\n",
        "#reorder columns to move State, Geo_Name and Geo_Type to front; also going to drop some values\n",
        "cols = merged.columns.tolist()\n",
        "cols = ['GEO_ID', 'RESP_DATE', 'State', 'Geo_Name', 'Region', 'Geo_Type', \n",
        "        'CRRINT', 'not_int', 'not_int_pct', 'CRRALL']\n",
        "merged = merged[cols]\n",
        "merged = merged.rename(columns={'CRRINT':'internet', 'CRRALL':'2020_rate'})\n",
        "#merged"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppli4PGC4oZd",
        "colab_type": "text"
      },
      "source": [
        "### States"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxWiGJyALk8C",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxRHegvy4oZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create df with response rate by state\n",
        "states2020 = merged[merged['Geo_Type'] == 'State']\n",
        "states2020 = states2020.rename(columns={\"internet\": \"state_internet\", \n",
        "                                        \"not_int\" : \"state_not_int\", \n",
        "                                        'not_int_pct' : 'state_not_int_pct',\n",
        "                                        \"2020_rate\" : \"2020_state_rate\"})\n",
        "\n",
        "# print df and sort by highest cumulative response rate\n",
        "#states2020.sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDPo55jgLtGy",
        "colab_type": "text"
      },
      "source": [
        "#### Join 2010 states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HDvnJhF4oaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in csvs with 2010 response data for states\n",
        "states2010 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/states2010.csv')\n",
        "\n",
        "# merge with 2020 states\n",
        "states = pd.merge(states2020, states2010, on='State')\n",
        "#get the column names\n",
        "cols = states.columns.tolist()\n",
        "#only select columns we want\n",
        "cols = ['GEO_ID', 'State', 'Region',\n",
        " '2020_state_rate', '2010_rate', '2000_rate']\n",
        "states = states[cols]\n",
        "states = states.rename(columns={'2000_rate':'2000_state_rate', '2010_rate':'2010_state_rate'})\n",
        "\n",
        "#create column with difference in 2010 vs 2020 response rate\n",
        "states['10_20_state_difference'] = states['2020_state_rate'] - states['2010_state_rate']\n",
        "\n",
        "#print table sorted by 10-20 difference largest ---> smallest\n",
        "#states.sort_values(by=['2000_state_rate'], ascending=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QutNTWkb4oZN",
        "colab_type": "text"
      },
      "source": [
        "### Census Tracts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYFZkXWy_ehB",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Tracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "poLTe8ZR4oZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select just census tract geo types\n",
        "tracts2020 = merged[merged['Geo_Type'].str.contains(\"Tract\")]\n",
        "#rename column\n",
        "tracts2020 = tracts2020.rename(columns={\"2020_rate\": \"2020_tract_rate\",\n",
        "                                        'not_int':'tract_not_int',\n",
        "                                        'not_int_pct':'tract_not_int_pct'})\n",
        "# sort by highest cumulative response rate\n",
        "#tracts2020.sort_values(by='2020_tract_rate', ascending=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHSpstWKIYJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tract rates compared to state averages\n",
        "tract2020states = pd.merge(tracts2020, states, on=['State', 'Region'])\n",
        "tract2020states = tract2020states[['GEO_ID_x', 'State', 'Geo_Name', 'Geo_Type', 'Region','2020_tract_rate', '2020_state_rate', '2010_state_rate', '10_20_state_difference']]\n",
        "tract2020states = tract2020states.rename(columns={'GEO_ID_x':'GEO_ID'})\n",
        "tract2020states['2020_tract_st_diff'] = tract2020states['2020_tract_rate'] - tract2020states['2020_state_rate']\n",
        "#tract2020states.sort_values(by=['2020_tract_st_diff'])\n",
        "#merging tracts with states will drop tribal tracts (as they have no state), so those are examined separately below"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw37IfN-MoJt",
        "colab_type": "text"
      },
      "source": [
        "#### Join 2010 tract rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzl46WTuLqog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in csvs with 2010 response data for tracts and states\n",
        "tracts2010 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/2010responserate.csv')\n",
        "#rename this column\n",
        "tracts2010 = tracts2010.rename(columns={'FSRR2010':'2010_tract_rate'})\n",
        "#tracts2010"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8wlaOo84oZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c89d9f2-130e-4485-8e4b-a373daf963e8"
      },
      "source": [
        "## difference in row numbers: both tract dfs have 84519 rows, but when joined only 84093\n",
        "# Identify what values are in tracts2010 and not in tracts2020\n",
        "key_diff1 = set(tracts2010.GEO_ID).difference(tracts2020.GEO_ID)\n",
        "len(key_diff1)\n",
        "#key_diff1\n",
        "\n",
        "# Identify what values are in tracts2020 and not in tracts2010\n",
        "key_diff2 = set(tracts2020.GEO_ID).difference(tracts2010.GEO_ID)\n",
        "len(key_diff2)\n",
        "#key_diff2\n",
        "\n",
        "# 2010 rates do not include tribal tracts while 2020 tracts are missing some \n",
        "# tracts in a multitude of states, likely due to a change in tract boundaries. \n",
        "# Those differences account for 426 tracts, which is .5% of the original 84519 \n",
        "# tracts. As these tracts comprise a small percentage, they can be dropped. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkzjcuo4oZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge with 2020 tracts\n",
        "tracts = pd.merge(tract2020states, tracts2010, on='GEO_ID')\n",
        "#get column names\n",
        "cols = tracts.columns.tolist()\n",
        "#select only columns we want\n",
        "cols = ['Geo_Name','county', 'State_y', 'Region', 'Geo_Type', '2020_tract_rate', '2010_tract_rate', '2020_tract_st_diff', '2020_state_rate', '2010_state_rate', '10_20_state_difference']\n",
        "tracts = tracts[cols]\n",
        "#rename weird column name\n",
        "tracts = tracts.rename(columns={'State_y':'State'})\n",
        "#print df sorted largest --> smallest 2010 rate\n",
        "#tracts.sort_values(by='2010_tract_rate', ascending=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19V3l294oZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#how many null 2010 response values are there: 531, which is .6% of all rows, 84093\n",
        "is_temp = tracts.isnull()\n",
        "no_2010 = is_temp.any(axis=1)\n",
        "no_2010 = tracts[no_2010]\n",
        "no_2010.sort_values(by=\"2010_tract_rate\")\n",
        "\n",
        "#due to the low percentage, these null values will be discarded\n",
        "tracts = tracts.dropna(axis=0)\n",
        "#check they'd discraded\n",
        "#tracts.sort_values(by='2010_tract_rate')\n",
        "#there are no 2010 na values, so all were dropped"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1oLIOrq4oZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create column with difference in 2010 vs 2020 response rate\n",
        "tracts['10_20_tract_difference'] = tracts['2020_tract_rate'] - tracts['2010_tract_rate']\n",
        "#sort df largest --> smallest 10-20 difference\n",
        "#tracts.sort_values(by='10_20_tract_difference', ascending=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftKA9hxg4oaM",
        "colab_type": "text"
      },
      "source": [
        "### Demographic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zeTAJAu4oaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load both sets of demographic data, join\n",
        "temp1 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/demographics1_working.csv')\n",
        "temp2 = pd.read_csv('https://raw.githubusercontent.com/tdiffendal/USAT/master/census-responses/demographics2_working.csv')\n",
        "demo = pd.merge(temp1, temp2, on=['GISJOIN', \"YEAR\", \"STATE\", \"STATEA\", \n",
        "                                              'COUNTY', 'COUNTYA', 'TRACTA', \n",
        "                                              'Geo_Name', 'NAME_E'])\n",
        "\n",
        "# merge to create new df with response rates and demos for all tracts\n",
        "temp = pd.merge(tracts, demo, on='Geo_Name')\n",
        "\n",
        "#create new column adding up pop with rent > 30% income (homelessness marker)\n",
        "temp['rent_30_more'] = (temp['rent_30_34.9'] + temp['rent_35_39.9'] \n",
        "+ temp['rent_40_49.9'] + temp['rent_50_over'])\n",
        "# check to see if column created\n",
        "#pd.set_option('display.max_columns', 100)\n",
        "#temp"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EoaTaJXA4oaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.std()Returns the standard deviation of each column\n",
        "#df.corr()Returns the correlation between columns in a data frame\n",
        "\n",
        "#In order to get # of null/missing values for each column, run \n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.isnull(temp).sum()\n",
        "\n",
        "# make a dataframe of all rows with na value\n",
        "temp1 = temp[temp.isna().any(axis=1)]\n",
        "temp1\n",
        "# how many nas in each state\n",
        "temp2 = temp1['State'].value_counts()\n",
        "temp2 = pd.DataFrame(temp2)\n",
        "temp2 = temp2.reset_index().rename(columns={'index':'state', 'State':'count_na'})\n",
        "temp2\n",
        "#compare to total \n",
        "temp3 = temp['State'].value_counts()\n",
        "temp3 = pd.DataFrame(temp3)\n",
        "temp3 = temp3.reset_index().rename(columns={'index':'state', 'State':'count'})\n",
        "temp3\n",
        "\n",
        "#see what percent of state values of na\n",
        "#Puerto Rico will lose the greatest % if these are dropped\n",
        "temp4 = pd.merge(temp2, temp3, on=['state'])\n",
        "temp4['na_percent'] = (temp4['count_na']*100) / temp4['count']\n",
        "temp4\n",
        "\n",
        "#how many total nas? --> 1171\n",
        "sum(temp4['count_na'])\n",
        "\n",
        "#nas account for what total % of all rows --> 1.82\n",
        "(sum(temp4['count_na'])*100) / sum(temp4['count'])\n",
        "\n",
        "#Less than 2% of total, so for now will drop those rows\n",
        "# before df had 64413 rows\n",
        "df = temp.dropna()    #now has 63242 rows, 1171 difference (total # nas)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_8zDZ3ghLTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if any nas\n",
        "#pd.set_option('display.max_rows', None)\n",
        "#print(pd.isnull(df).sum())\n",
        "\n",
        "#still 52 states? (50 + DC and PR)\n",
        "#print(\"Number states: \", len(df['State'].unique()))\n",
        "\n",
        "#compare tract numbers now to before na drop\n",
        "temp1 = pd.DataFrame(temp.groupby('State')['Geo_Name'].nunique()).rename(columns={'Geo_Name':'beforeDrop'})\n",
        "temp2 = pd.DataFrame(df.groupby('State')['Geo_Name'].nunique()).rename(columns={'Geo_Name':'afterDrop'})\n",
        "temp3 = pd.merge(temp1, temp2, left_index = True, right_index=True)\n",
        "#number tracts dropped from each state\n",
        "temp3['numDrop'] = temp3['beforeDrop'] - temp3['afterDrop']\n",
        "# the percentage of total tracts dropped\n",
        "temp3['dropPct'] = temp3['numDrop']*100 / temp3['beforeDrop']\n",
        "#temp3 #puerto rico loses the most tracts at 5.7%"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo_-Pu9E4oaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#return column size\n",
        "pd.set_option('display.max_columns', 15)\n",
        "pd.set_option('display.max_row', 50)\n",
        "\n",
        "#print df with no nas\n",
        "#df.to_csv(\"all_rates_demos_merged.csv\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdZ0zN4nA1ek",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAjKrWdeyR9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "aab01855-3272-41f5-c7d5-d8ce3a8374f1"
      },
      "source": [
        "##see all dfs in memory\n",
        "%whos DataFrame\n",
        "\n",
        "#### Existing DFs:\n",
        "\n",
        "#dataframe with all years, states, tracts, demographics\n",
        "#df\n",
        "\n",
        "#2010 and 2020 states\n",
        "#states\n",
        "\n",
        "#2010 States\n",
        "#states2010\n",
        "\n",
        "#2020 States\n",
        "#states2020\n",
        "\n",
        "#2010 and 2020 tracts and states\n",
        "#tracts\n",
        "\n",
        "#2020 tracts paired with states, includes int data\n",
        "#tracts2020states\n",
        "\n",
        "#ignore: crosswalk, demo, demo1, demo2, df1, df2, df3, df4, df5\n",
        "        #hm, hmm, hmmm, initial_df, merged1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable          Type         Data/Info\n",
            "----------------------------------------\n",
            "crosswalk         DataFrame                   GEO_ID    <...>[125338 rows x 4 columns]\n",
            "demo              DataFrame                  GISJOIN    <...>[73976 rows x 91 columns]\n",
            "df                DataFrame                       Geo_Na<...>63242 rows x 103 columns]\n",
            "initial_df        DataFrame                   GEO_ID   R<...>123252 rows x 22 columns]\n",
            "is_temp           DataFrame           Geo_Name  county  <...>[84093 rows x 11 columns]\n",
            "merged            DataFrame                         GEO_<...>123250 rows x 10 columns]\n",
            "no_2010           DataFrame                         Geo_<...>\\n[531 rows x 11 columns]\n",
            "regions           DataFrame              State       Reg<...>\\n\\n[54 rows x 2 columns]\n",
            "states            DataFrame             GEO_ID          <...>\\n\\n[52 rows x 7 columns]\n",
            "states2010        DataFrame                State Geo_Typ<...>\\n\\n[52 rows x 4 columns]\n",
            "states2020        DataFrame                 GEO_ID   RES<...>n\\n[52 rows x 10 columns]\n",
            "temp              DataFrame                       Geo_Na<...>64413 rows x 103 columns]\n",
            "temp1             DataFrame                    beforeDro<...>\\n\\n[52 rows x 1 columns]\n",
            "temp2             DataFrame                    afterDrop<...>\\n\\n[52 rows x 1 columns]\n",
            "temp3             DataFrame                    beforeDro<...>\\n\\n[52 rows x 4 columns]\n",
            "temp4             DataFrame                state  count_<...>\\n\\n[51 rows x 4 columns]\n",
            "tract2020states   DataFrame                         GEO_<...>[84093 rows x 10 columns]\n",
            "tracts            DataFrame                        Geo_N<...>[83562 rows x 12 columns]\n",
            "tracts2010        DataFrame                           NA<...>n[84519 rows x 8 columns]\n",
            "tracts2020        DataFrame                          GEO<...>[84519 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUrmR-IrfcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0f90ec98-7225-4454-efb8-326f51d19285"
      },
      "source": [
        "i = states.mean(axis=0)['2020_state_rate']\n",
        "print(\n",
        "    i,\n",
        "    \"% is the current nationwide average and\",\n",
        "    np.sum(df['2020_state_rate'] > i),\n",
        "    \"states exceed that\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60.35576923076923 % is the current nationwide average and 39079 states exceed that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKSDVX0vZAew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "243a9d76-09a7-43c0-f987-fb56fb52ec02"
      },
      "source": [
        "#how many tracts are > than state avg?\n",
        "\n",
        "#tract2020States.count(tract2020States['2020_tract_st_diff'] > 0)\n",
        "print(np.sum(tract2020states['2020_tract_st_diff'] > 0), \"tracts out of\", \n",
        "      len(tract2020states), \n",
        "      \"total (\", \n",
        "      (np.sum(tract2020states['2020_tract_st_diff'] > 0) * 100) / len(tract2020states), \"% )\",\n",
        "      \"currently have greater census response rates than their state average\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44995 tracts out of 84093 total ( 53.506237142211596 % ) currently have greater census response rates than their state average\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuG9IMvlwcHv",
        "colab_type": "text"
      },
      "source": [
        "### National Comparative Rankings 2010 vs 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iwBMqvP9xxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Discrepancies? Shouldn't these all match up?\n",
        "\n",
        "print(\n",
        "  \"2010 State Resonse Average from states data:\",\n",
        "    states.mean(axis=0)['2010_state_rate'], \"\\n\",\n",
        "  \"2010 States Response Average from df data:\",\n",
        "    df.mean(axis=0)['2010_state_rate'], \"\\n\",\n",
        "  \"2010 Tract Response Average from df data:\",\n",
        "    df.mean(axis=0)['2010_tract_rate']\n",
        ")\n",
        "## why are these the same as above what's the difference between an average and a totallllllll\n",
        "print(\n",
        "  \"2010 State Resonse Total from states data:\",\n",
        "    (states['2010_state_rate'].sum()) / (states.shape[0]), \"\\n\",\n",
        "  \"2010 States Response Total from df data:\",\n",
        "    (df['2010_state_rate'].sum()) / (df.shape[0]), \"\\n\",\n",
        "  \"2010 Tract Response Total from df data:\",\n",
        "    (df['2010_tract_rate'].sum()) / (df.shape[0])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qw6ix7B4oaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average difference between current state rates and 2010 state rates as of 6/15/20\n",
        "#takes a while to run so commented out\n",
        "#df.mean(axis=0)['10_20_state_difference']\n",
        "\n",
        "#average 2020 response rate across states?\n",
        "print(\n",
        "  \"2020 State Resonse Average from states data:\",\n",
        "    states.mean(axis=0)['2020_state_rate'], \"\\n\",\n",
        "  \"2020 States Response Average from df data:\",\n",
        "    df.mean(axis=0)['2020_state_rate'], \"\\n\",\n",
        "  \"2020 Tract Response Average from df data:\",\n",
        "    df.mean(axis=0)['2020_tract_rate']\n",
        ")\n",
        "\n",
        "print(\n",
        "  \"2020 State Resonse Total from states data:\",\n",
        "    (states['2020_state_rate'].sum()) / (states.shape[0] * 100), \"\\n\",\n",
        "  \"2020 States Response Total from df data:\",\n",
        "    (df['2020_state_rate'].sum()) / (df.shape[0] * 100), \"\\n\",\n",
        "  \"2020 Tract Response Total from df data:\",\n",
        "    (df['2020_tract_rate'].sum()) / (df.shape[0] * 100)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBtQ-tkD4oaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference by region\n",
        "states.groupby('Region').mean().sort_values(by='10_20_state_difference', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db386fTQ4iiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assign ranks to states based on comparative response rate\n",
        "states['2020_rank'] = states['2020_state_rate'].rank(method='max', ascending=False)\n",
        "states['2010_rank'] = states['2010_state_rate'].rank(method='max', ascending=False)\n",
        "\n",
        "#pull ranks into separate dataframe\n",
        "state_ranks = states[['State', '2020_rank', '2010_rank']].sort_values(by='2020_rank')\n",
        "\n",
        "#show change in rank from 2010 to 2020\n",
        "#negative number means a state has a lower 2020 response rate and has gone down in rankings\n",
        "state_ranks['rank_change'] = state_ranks['2010_rank'] - state_ranks['2020_rank']\n",
        "state_ranks.sort_values(by='rank_change', ascending=True)\n",
        "\n",
        "#see how many states only changed 2 or fewer positions\n",
        "#small_change = state_ranks[state_ranks.rank_change.between(-2, 2, inclusive=True)].sort_values(by='rank_change')\n",
        "#small_change\n",
        "#16 states have stayed ~similar in the rankings, and this seems to impact\n",
        "#states with both high and low response rates\n",
        "#small_change.mean(axis=0)['2020_rank']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjhY7qa-UCO",
        "colab_type": "text"
      },
      "source": [
        "### Internet Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Ry4-MtiXkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbOu9mByHce0",
        "colab_type": "text"
      },
      "source": [
        "Internet usage is only available for 2020 rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7DBXHjYM-Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Percent of response rate not from internet\n",
        "\n",
        "states2020.sort_values(by='state_not_int_pct', ascending=False)\n",
        "states2020.mean(axis=0)['state_not_int_pct']\n",
        "states2020.mean(axis=0)['state_not_int']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkuAB-vDkKvv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c4Kc5YV4oZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average non internet response rate\n",
        "states2020.groupby(by='Region').mean().sort_values(by='state_internet', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1moWoRN4oZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# highest non-internet response rate (not_int)\n",
        "states2020.sort_values(by='state_not_int', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajtMfXEB4oZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['state_not_int']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5-66yFC4oZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['state_internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rS4qL6f4oZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states2020.mean(axis=0)['2020_state_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZPt0jX4oZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Without Puerto Rico\n",
        "\n",
        "#make non-pr df\n",
        "no_pr = states2020[states2020['State'] != 'Puerto Rico']\n",
        "\n",
        "# average internet response\n",
        "no_pr.mean(axis=0)['state_internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Qif8pR4oZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average overall response rate\n",
        "no_pr.mean(axis=0)['2020_state_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tN9xyjpHg9t",
        "colab_type": "text"
      },
      "source": [
        "### Region Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWUbAvs4oZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average by region\n",
        "# NOTE as tribal tracts are not assigned to a state they do not have a corresponding region and thus are not counted in the regional calculations\n",
        "states.groupby('Region').mean().sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AggzDxDA4oZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference as of 6/15/20\n",
        "#this can take a while to run so is commented out unless needed\n",
        "#tracts.mean(axis=0)['10_20_tract_difference']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZmwRdx4oaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# average difference by region\n",
        "tracts.groupby('Region').mean().sort_values(by='10_20_tract_difference', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qug7mLZl-rCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tract average differences vs state rates\n",
        "tracts.groupby('State').mean().sort_values(by='2020_state_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmLScMTr4oZQ",
        "colab_type": "text"
      },
      "source": [
        "### Tribal tracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSdZysHS4oZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create df with response rates in tribal tracts\n",
        "tribal = tracts2020[tracts2020['Geo_Type'].str.contains(\"Tribal\")]\n",
        "tribal.sort_values(by='2020_tract_rate', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVcFRIn4oZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### tribal areas and tracts stats\n",
        "\n",
        "#mean non internet response\n",
        "tribal.mean(axis=0)['tract_not_int'] #8.37%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjVmQ5e_4oZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean internet response rate\n",
        "tribal.mean(axis=0)['internet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euvyx-gL4oZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean overall response rate\n",
        "tribal.mean(axis=0)['2020_tract_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5b3R3834oZb",
        "colab_type": "text"
      },
      "source": [
        "### Tracts with 0 overall response rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eukXYcJx4oZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Tracts with 0 cumulative response rate: 28\n",
        "is_zero = tracts['2020_tract_rate'] == 0.0\n",
        "zeros = tracts[is_zero]\n",
        "zeros.sort_values(by='State')\n",
        "\n",
        "## Tracts with 0 cumulative response rate: 28\n",
        "\n",
        "#make dataframe of states with # tracts with 0%, number total tracts, and what % of total tracts are 0\n",
        "temp = pd.DataFrame(zeros['State'].value_counts())\n",
        "temp2 = pd.DataFrame(tracts['State'].value_counts())\n",
        "temp3 = pd.merge(temp, temp2, right_index=True, left_index=True)\n",
        "#rename the columns\n",
        "temp3 = temp3.rename(columns={\"State_x\": \"0_tracts\", \"State_y\" : \"total_tracts\"})\n",
        "#compute percentage\n",
        "temp3['0_percent'] = temp3['0_tracts'] * 100 / temp3['total_tracts']\n",
        "temp3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPFHo4nO4oaU",
        "colab_type": "text"
      },
      "source": [
        "## Regressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn2rfAXWrfBe",
        "colab_type": "text"
      },
      "source": [
        "### With Puerto Rico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKBskyL7s-xu",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SHooFoBrrYEc",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = df[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = df[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "print(model20.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cbIp7LrSrYEg",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PToZ-lAorYEh"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R_dZfFsOrYEi",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "print(norm_model20.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fuv49LFwrYEk",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ECGhvxrhrYEl"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPMtG8ozrYEm",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = df[['total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = df[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "print(model10.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v_9tWG5drYEp",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "43-byZJzrYEq"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4bR0BjIrYEr",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "print(norm_model10.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ro4o8GDNrYEs",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXjoZqoZubCg",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "co5U07EArYEu",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = df[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other', 'income_poverty_ratio', 'per_capita_income',\n",
        " 'civilian_employed', 'civilian_unemployed',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income','rent_30_more',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer',\n",
        " 'us_born', 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = df[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "print(model_ed.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lm1iHnSurYEw",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Okny5FRDrYEx",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "print(norm_model_ed.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nccgx89crqt4",
        "colab_type": "text"
      },
      "source": [
        "### Without Puerto Rico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbsOPCbT4oaU",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd46DCij4oaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "#df without puerto rico for regression \n",
        "no_pr = df[df['Region'] != 'Puerto Rico']\n",
        "#this is different from earlier code no_pr = states[states.State != 'Puerto Rico']\n",
        "#earlier code omitted Puerto Rico from state level data. this eliminates from tract level data\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = no_pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = no_pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZthvp0R4oaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0npA7T4oaZ",
        "colab_type": "text"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85hPJc_O4oaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "norm_model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQfOymD4oab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29JVbcP4oad",
        "colab_type": "text"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xixKDYjY4oad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = no_pr[['total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = no_pr[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfY5LKEc4oag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3fc89-J4oaj",
        "colab_type": "text"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlwfXss24oaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "norm_model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM2yaM3d4oal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhxSdjQsFBs",
        "colab_type": "text"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKbhPPF44oao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = no_pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other', 'income_poverty_ratio', 'per_capita_income',\n",
        " 'civilian_employed', 'civilian_unemployed',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income','rent_30_more',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer',\n",
        " 'us_born', 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = no_pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_WySxM4oaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceNe_aTSasfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "norm_model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfVDv7agtnz_",
        "colab_type": "text"
      },
      "source": [
        "### Puerto Rico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1AaDVLtr9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create df with just puerto rico\n",
        "is_pr = df['Region'] == 'Puerto Rico'\n",
        "pr = df[is_pr]\n",
        "pr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tYdF-C1cu1y8"
      },
      "source": [
        "#### 2020 regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RlidAAwwu1y-",
        "colab": {}
      },
      "source": [
        "### 2020 Multi-regression\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables20 = pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target20 = pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build model and print summary\n",
        "model20 = sm.OLS(target20, variables20).fit()\n",
        "model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cvkw34rku1zA",
        "colab": {}
      },
      "source": [
        "### 2020 linear regressions for each variable\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables20.columns.tolist()\n",
        "#build linear model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to store loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit linear model to variable\n",
        "    regr.fit(variables20[[i]], target20)\n",
        "    #save model variable name, intercept, coef and r^2 to list\n",
        "    rows.append([i, regr.intercept_, regr.coef_, regr.score(variables20[[i]], target20)])\n",
        "\n",
        "#turn list into df with these column names\n",
        "linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets lol\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['coefficient'] = linears20['coefficient'].str.get(0)\n",
        "linears20['intercept'] = linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted coefs largest --> smallest\n",
        "linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JVacRXRu1zB"
      },
      "source": [
        "#### Normalized 2020 inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5KAHuRvHu1zC",
        "colab": {}
      },
      "source": [
        "### 2020 Multi regression with normalized variables\n",
        "\n",
        "#normalize variable values\n",
        "norm_variables20 = (variables20 - variables20.min()) / (variables20.max() - variables20.min())\n",
        "\n",
        "#build normalized multi-regress model and print summary\n",
        "norm_model20 = sm.OLS(target20, norm_variables20).fit()\n",
        "norm_model20.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2jTl88Abu1zE",
        "colab": {}
      },
      "source": [
        "#2020 normalized linear regressions for each variable\n",
        "\n",
        "# linear regression for each variable 'i'\n",
        "cols = norm_variables20.columns.tolist()\n",
        "# create model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#empty list for loop results\n",
        "rows = []\n",
        "#loop through each variable\n",
        "for i in cols:\n",
        "    #fit model to each variable\n",
        "    norm_regr.fit(norm_variables20[[i]], target20)\n",
        "    #add model results to list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_, \n",
        "                 norm_regr.score(norm_variables20[[i]], target20)])\n",
        "\n",
        "#turn list into dataframe\n",
        "norm_linears20 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['coefficient'] = norm_linears20['coefficient'].str.get(0)\n",
        "norm_linears20['intercept'] = norm_linears20['intercept'].str.get(0)\n",
        "\n",
        "#print df ordered by largest to smallest coef\n",
        "norm_linears20.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eBcoXR_Iu1zG"
      },
      "source": [
        "#### 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRFQpznKu1zG",
        "colab": {}
      },
      "source": [
        "### 2010 multi regression\n",
        "\n",
        "#put all variables for predicting 2010 rates in dataframe\n",
        "variables10 = pr[['total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone',\n",
        " 'other_alone', 'two_or_more', 'two_more_including_other',\n",
        " 'two_more_excluding_other', 'total_education', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master', 'prof_school', 'doctorate', 'language_total',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other_indo_euro', 'lang_asian_pacific_island',\n",
        " 'lang_other', 'income_poverty_ratio', 'income_poverty_under_half',\n",
        " 'income_poverty_half_.99', 'income_povery_1_1.24',\n",
        " 'income_poverty_1.25_1.49', 'income_poverty_1.5_1.84',\n",
        " 'income_poverty_1.85_1.99', 'income_poverty_2_over',\n",
        " 'median_household_income', 'per_capita_income',\n",
        " 'employment_total', 'labor_force', 'civilian_labor_force',\n",
        " 'civilian_employed', 'civilian_unemployed', 'armed_forces',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'total_occupied_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income',\n",
        " 'rent_less_10', 'rent_10_14.9', 'rent_15_19.9', 'rent_20_24.9',\n",
        " 'rent_25_29.9', 'rent_30_34.9', 'rent_35_39.9', 'rent_40_49.9',\n",
        " 'rent_50_over', 'rent_30_more', 'rent_not_computed', 'total_computer_status',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer', 'us_pop',\n",
        " 'us_born', 'us_territory_born', 'us_born_abroad',\n",
        " 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2010 response rates - in separate dataframe\n",
        "target10 = pr[[\"2010_tract_rate\"]]\n",
        "\n",
        "#create model and print summary table\n",
        "model10 = sm.OLS(target10, variables10).fit()\n",
        "model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6CS4y7X_u1zI",
        "colab": {}
      },
      "source": [
        "### 2010 linear regression for each variable\n",
        "\n",
        "#list of variable names\n",
        "cols = variables10.columns.tolist()\n",
        "#build multi-reg model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list for loop results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit a model to the current variable\n",
        "    regr.fit(variables10[[i]], target10)\n",
        "    #save the model's resulting variable name, intercept, coef, and r^2\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame\n",
        "linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['coefficient'] = linears10['coefficient'].str.get(0)\n",
        "linears10['intercept'] = linears10['intercept'].str.get(0)\n",
        "\n",
        "#print data frame ordered coefficient largest --> smallest\n",
        "linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-pAJMVeu1zK"
      },
      "source": [
        "#### Normalized 2010 Regressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BtAXZ8Zeu1zK",
        "colab": {}
      },
      "source": [
        "### 2010 normalized multi-regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables10 = (variables10 - variables10.min()) / (variables10.max() - variables10.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model10 = sm.OLS(target10, norm_variables10).fit()\n",
        "norm_model10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wxTWDr54u1zM",
        "colab": {}
      },
      "source": [
        "###2010 normalized linear regressions for each variable\n",
        "\n",
        "#create list of variable names\n",
        "cols = norm_variables10.columns.tolist()\n",
        "#build the model\n",
        "norm_regr = linear_model.LinearRegression()\n",
        "#create empty list for model results\n",
        "rows = []\n",
        "#cycle through variables\n",
        "for i in cols:\n",
        "    #do the linear regression on the current variable\n",
        "    norm_regr.fit(norm_variables10[[i]], target10)\n",
        "    #add the corresponding variable name, intercept, coefficient and r-squared to the list\n",
        "    rows.append([i, norm_regr.intercept_, norm_regr.coef_,\n",
        "                norm_regr.score(norm_variables10[[i]], target10)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "norm_linears10 = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['coefficient'] = norm_linears10['coefficient'].str.get(0)\n",
        "norm_linears10['intercept'] = norm_linears10['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient\n",
        "norm_linears10.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KsqdFNHru1zN"
      },
      "source": [
        "#### 2020 Edited Regressions\n",
        "Edited = Run regressions with fewer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnSLhYOwu1zN",
        "colab": {}
      },
      "source": [
        "### 2020 edited multi-regressions\n",
        "\n",
        "#put all variables for predicting 2020 rates in dataframe\n",
        "variables_ed = pr[['2010_tract_rate','total_population', \n",
        " 'white_alone', 'black_alone', 'amerindian_alone', 'asian_alone', \n",
        " 'pacific_islander_alone', 'no_school',\n",
        " 'some_school', 'diploma', 'ged', 'some_college', 'associate',\n",
        " 'bachelor', 'master',\n",
        " 'lang_english_only', 'lang_spanish', 'lang_spanish_limited_english', \n",
        " 'lang_other', 'income_poverty_ratio', 'per_capita_income',\n",
        " 'civilian_employed', 'civilian_unemployed',\n",
        " 'not_labor_force', 'total_houses', 'occupied_houses',\n",
        " 'vacant_houses', 'owner_occupied',\n",
        " 'renter_occupied', 'median_gross_rent', 'rent_to_income','rent_30_more',\n",
        " 'has_computer', 'dial_up_computer', 'broadband_computer',\n",
        " 'no_internet_computer', 'no_computer',\n",
        " 'us_born', 'us_naturalization', 'not_us_citizen']]\n",
        "\n",
        "#what we want to predict - 2020 response rates - in dataframe\n",
        "target_ed = pr[[\"2020_tract_rate\"]]\n",
        "\n",
        "#build and fit the multi-regression model\n",
        "model_ed = sm.OLS(target_ed, variables_ed).fit()\n",
        "#print out the model summary table\n",
        "model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAFrD4JRu1zQ",
        "colab": {}
      },
      "source": [
        "### 2020 edited linear regressions\n",
        "\n",
        "#create list of variable names\n",
        "cols = variables_ed.columns.tolist()\n",
        "#build the model\n",
        "regr = linear_model.LinearRegression()\n",
        "#create empty list to append results\n",
        "rows = []\n",
        "\n",
        "#loop through variables\n",
        "for i in cols:\n",
        "    #fit the model\n",
        "    regr.fit(variables_ed[[i]], target_ed)\n",
        "    #put model variable name, intercept, coef and r^2 in list\n",
        "    rows.append([i, regr.intercept_, regr.coef_,\n",
        "                regr.score(variables_ed[[i]], target_ed)])\n",
        "\n",
        "#turn list into data frame with these column names\n",
        "linears_ed = pd.DataFrame(rows, columns=['variable', 'intercept', 'coefficient', 'r-squared'])\n",
        "\n",
        "#remove square brackets\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['coefficient'] = linears_ed['coefficient'].str.get(0)\n",
        "linears_ed['intercept'] = linears_ed['intercept'].str.get(0)\n",
        "\n",
        "#print df sorted by coefficient largest --> smallest\n",
        "linears_ed.sort_values(by='coefficient', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QGqYmMH6u1zS",
        "colab": {}
      },
      "source": [
        "### normalized 2020 edited variables multi regression\n",
        "\n",
        "#normalize the variables\n",
        "norm_variables_ed = (variables_ed - variables_ed.min()) / (variables_ed.max() - variables_ed.min())\n",
        "\n",
        "#build normalized model and print summary\n",
        "norm_model_ed = sm.OLS(target_ed, norm_variables_ed).fit()\n",
        "norm_model_ed.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}